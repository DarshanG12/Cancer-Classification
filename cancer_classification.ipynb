{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3666,
     "status": "ok",
     "timestamp": 1657210992194,
     "user": {
      "displayName": "Darshan Darshu",
      "userId": "08066444614316366436"
     },
     "user_tz": -330
    },
    "id": "0X2JdQIdiCEn"
   },
   "outputs": [],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 436,
     "status": "ok",
     "timestamp": 1657210992623,
     "user": {
      "displayName": "Darshan Darshu",
      "userId": "08066444614316366436"
     },
     "user_tz": -330
    },
    "id": "82RoSQZziEgJ"
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"cancer_classification(1).csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 334
    },
    "executionInfo": {
     "elapsed": 434,
     "status": "ok",
     "timestamp": 1657210998517,
     "user": {
      "displayName": "Darshan Darshu",
      "userId": "08066444614316366436"
     },
     "user_tz": -330
    },
    "id": "BUvXllQ_i1d7",
    "outputId": "38a9b035-f83b-4fa3-9e42-31d24bc401a0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-1849e868-53d4-4b6a-9fcc-b021909f3d6d\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1849e868-53d4-4b6a-9fcc-b021909f3d6d')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-1849e868-53d4-4b6a-9fcc-b021909f3d6d button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-1849e868-53d4-4b6a-9fcc-b021909f3d6d');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                 0.07871  ...          17.33           184.60      2019.0   \n",
       "1                 0.05667  ...          23.41           158.80      1956.0   \n",
       "2                 0.05999  ...          25.53           152.50      1709.0   \n",
       "3                 0.09744  ...          26.50            98.87       567.7   \n",
       "4                 0.05883  ...          16.67           152.20      1575.0   \n",
       "\n",
       "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   worst symmetry  worst fractal dimension  target  \n",
       "0          0.4601                  0.11890       0  \n",
       "1          0.2750                  0.08902       0  \n",
       "2          0.3613                  0.08758       0  \n",
       "3          0.6638                  0.17300       0  \n",
       "4          0.2364                  0.07678       0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 481,
     "status": "ok",
     "timestamp": 1657211002419,
     "user": {
      "displayName": "Darshan Darshu",
      "userId": "08066444614316366436"
     },
     "user_tz": -330
    },
    "id": "iZFiYwzujvrO",
    "outputId": "9a782bd3-d9b6-4beb-c1e9-2b9993f1343d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mean radius                0\n",
       "mean texture               0\n",
       "mean perimeter             0\n",
       "mean area                  0\n",
       "mean smoothness            0\n",
       "mean compactness           0\n",
       "mean concavity             0\n",
       "mean concave points        0\n",
       "mean symmetry              0\n",
       "mean fractal dimension     0\n",
       "radius error               0\n",
       "texture error              0\n",
       "perimeter error            0\n",
       "area error                 0\n",
       "smoothness error           0\n",
       "compactness error          0\n",
       "concavity error            0\n",
       "concave points error       0\n",
       "symmetry error             0\n",
       "fractal dimension error    0\n",
       "worst radius               0\n",
       "worst texture              0\n",
       "worst perimeter            0\n",
       "worst area                 0\n",
       "worst smoothness           0\n",
       "worst compactness          0\n",
       "worst concavity            0\n",
       "worst concave points       0\n",
       "worst symmetry             0\n",
       "worst fractal dimension    0\n",
       "target                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1657211005439,
     "user": {
      "displayName": "Darshan Darshu",
      "userId": "08066444614316366436"
     },
     "user_tz": -330
    },
    "id": "K2UDfYmckKSj",
    "outputId": "534515ae-e2c4-4a86-a433-befd109bb8e6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    357\n",
       "0    212\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "executionInfo": {
     "elapsed": 1176,
     "status": "ok",
     "timestamp": 1657211010977,
     "user": {
      "displayName": "Darshan Darshu",
      "userId": "08066444614316366436"
     },
     "user_tz": -330
    },
    "id": "qPdwz0sWkdMl",
    "outputId": "2d958775-3708-4b39-ab5e-de5b1d9ed037"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f268398f350>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x=\"target\",data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1657211014873,
     "user": {
      "displayName": "Darshan Darshu",
      "userId": "08066444614316366436"
     },
     "user_tz": -330
    },
    "id": "p6xad5TZk-Cp",
    "outputId": "a9661167-bdee-4f84-c8dc-f4176442c0fb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-5ca9b37b-982b-4b3a-b8c8-52f2ed8b41a2\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>14.127292</td>\n",
       "      <td>19.289649</td>\n",
       "      <td>91.969033</td>\n",
       "      <td>654.889104</td>\n",
       "      <td>0.096360</td>\n",
       "      <td>0.104341</td>\n",
       "      <td>0.088799</td>\n",
       "      <td>0.048919</td>\n",
       "      <td>0.181162</td>\n",
       "      <td>0.062798</td>\n",
       "      <td>...</td>\n",
       "      <td>25.677223</td>\n",
       "      <td>107.261213</td>\n",
       "      <td>880.583128</td>\n",
       "      <td>0.132369</td>\n",
       "      <td>0.254265</td>\n",
       "      <td>0.272188</td>\n",
       "      <td>0.114606</td>\n",
       "      <td>0.290076</td>\n",
       "      <td>0.083946</td>\n",
       "      <td>0.627417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.524049</td>\n",
       "      <td>4.301036</td>\n",
       "      <td>24.298981</td>\n",
       "      <td>351.914129</td>\n",
       "      <td>0.014064</td>\n",
       "      <td>0.052813</td>\n",
       "      <td>0.079720</td>\n",
       "      <td>0.038803</td>\n",
       "      <td>0.027414</td>\n",
       "      <td>0.007060</td>\n",
       "      <td>...</td>\n",
       "      <td>6.146258</td>\n",
       "      <td>33.602542</td>\n",
       "      <td>569.356993</td>\n",
       "      <td>0.022832</td>\n",
       "      <td>0.157336</td>\n",
       "      <td>0.208624</td>\n",
       "      <td>0.065732</td>\n",
       "      <td>0.061867</td>\n",
       "      <td>0.018061</td>\n",
       "      <td>0.483918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.981000</td>\n",
       "      <td>9.710000</td>\n",
       "      <td>43.790000</td>\n",
       "      <td>143.500000</td>\n",
       "      <td>0.052630</td>\n",
       "      <td>0.019380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>0.049960</td>\n",
       "      <td>...</td>\n",
       "      <td>12.020000</td>\n",
       "      <td>50.410000</td>\n",
       "      <td>185.200000</td>\n",
       "      <td>0.071170</td>\n",
       "      <td>0.027290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156500</td>\n",
       "      <td>0.055040</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>11.700000</td>\n",
       "      <td>16.170000</td>\n",
       "      <td>75.170000</td>\n",
       "      <td>420.300000</td>\n",
       "      <td>0.086370</td>\n",
       "      <td>0.064920</td>\n",
       "      <td>0.029560</td>\n",
       "      <td>0.020310</td>\n",
       "      <td>0.161900</td>\n",
       "      <td>0.057700</td>\n",
       "      <td>...</td>\n",
       "      <td>21.080000</td>\n",
       "      <td>84.110000</td>\n",
       "      <td>515.300000</td>\n",
       "      <td>0.116600</td>\n",
       "      <td>0.147200</td>\n",
       "      <td>0.114500</td>\n",
       "      <td>0.064930</td>\n",
       "      <td>0.250400</td>\n",
       "      <td>0.071460</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>13.370000</td>\n",
       "      <td>18.840000</td>\n",
       "      <td>86.240000</td>\n",
       "      <td>551.100000</td>\n",
       "      <td>0.095870</td>\n",
       "      <td>0.092630</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>0.179200</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>...</td>\n",
       "      <td>25.410000</td>\n",
       "      <td>97.660000</td>\n",
       "      <td>686.500000</td>\n",
       "      <td>0.131300</td>\n",
       "      <td>0.211900</td>\n",
       "      <td>0.226700</td>\n",
       "      <td>0.099930</td>\n",
       "      <td>0.282200</td>\n",
       "      <td>0.080040</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>15.780000</td>\n",
       "      <td>21.800000</td>\n",
       "      <td>104.100000</td>\n",
       "      <td>782.700000</td>\n",
       "      <td>0.105300</td>\n",
       "      <td>0.130400</td>\n",
       "      <td>0.130700</td>\n",
       "      <td>0.074000</td>\n",
       "      <td>0.195700</td>\n",
       "      <td>0.066120</td>\n",
       "      <td>...</td>\n",
       "      <td>29.720000</td>\n",
       "      <td>125.400000</td>\n",
       "      <td>1084.000000</td>\n",
       "      <td>0.146000</td>\n",
       "      <td>0.339100</td>\n",
       "      <td>0.382900</td>\n",
       "      <td>0.161400</td>\n",
       "      <td>0.317900</td>\n",
       "      <td>0.092080</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>28.110000</td>\n",
       "      <td>39.280000</td>\n",
       "      <td>188.500000</td>\n",
       "      <td>2501.000000</td>\n",
       "      <td>0.163400</td>\n",
       "      <td>0.345400</td>\n",
       "      <td>0.426800</td>\n",
       "      <td>0.201200</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>0.097440</td>\n",
       "      <td>...</td>\n",
       "      <td>49.540000</td>\n",
       "      <td>251.200000</td>\n",
       "      <td>4254.000000</td>\n",
       "      <td>0.222600</td>\n",
       "      <td>1.058000</td>\n",
       "      <td>1.252000</td>\n",
       "      <td>0.291000</td>\n",
       "      <td>0.663800</td>\n",
       "      <td>0.207500</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5ca9b37b-982b-4b3a-b8c8-52f2ed8b41a2')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-5ca9b37b-982b-4b3a-b8c8-52f2ed8b41a2 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-5ca9b37b-982b-4b3a-b8c8-52f2ed8b41a2');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "       mean radius  mean texture  mean perimeter    mean area  \\\n",
       "count   569.000000    569.000000      569.000000   569.000000   \n",
       "mean     14.127292     19.289649       91.969033   654.889104   \n",
       "std       3.524049      4.301036       24.298981   351.914129   \n",
       "min       6.981000      9.710000       43.790000   143.500000   \n",
       "25%      11.700000     16.170000       75.170000   420.300000   \n",
       "50%      13.370000     18.840000       86.240000   551.100000   \n",
       "75%      15.780000     21.800000      104.100000   782.700000   \n",
       "max      28.110000     39.280000      188.500000  2501.000000   \n",
       "\n",
       "       mean smoothness  mean compactness  mean concavity  mean concave points  \\\n",
       "count       569.000000        569.000000      569.000000           569.000000   \n",
       "mean          0.096360          0.104341        0.088799             0.048919   \n",
       "std           0.014064          0.052813        0.079720             0.038803   \n",
       "min           0.052630          0.019380        0.000000             0.000000   \n",
       "25%           0.086370          0.064920        0.029560             0.020310   \n",
       "50%           0.095870          0.092630        0.061540             0.033500   \n",
       "75%           0.105300          0.130400        0.130700             0.074000   \n",
       "max           0.163400          0.345400        0.426800             0.201200   \n",
       "\n",
       "       mean symmetry  mean fractal dimension  ...  worst texture  \\\n",
       "count     569.000000              569.000000  ...     569.000000   \n",
       "mean        0.181162                0.062798  ...      25.677223   \n",
       "std         0.027414                0.007060  ...       6.146258   \n",
       "min         0.106000                0.049960  ...      12.020000   \n",
       "25%         0.161900                0.057700  ...      21.080000   \n",
       "50%         0.179200                0.061540  ...      25.410000   \n",
       "75%         0.195700                0.066120  ...      29.720000   \n",
       "max         0.304000                0.097440  ...      49.540000   \n",
       "\n",
       "       worst perimeter   worst area  worst smoothness  worst compactness  \\\n",
       "count       569.000000   569.000000        569.000000         569.000000   \n",
       "mean        107.261213   880.583128          0.132369           0.254265   \n",
       "std          33.602542   569.356993          0.022832           0.157336   \n",
       "min          50.410000   185.200000          0.071170           0.027290   \n",
       "25%          84.110000   515.300000          0.116600           0.147200   \n",
       "50%          97.660000   686.500000          0.131300           0.211900   \n",
       "75%         125.400000  1084.000000          0.146000           0.339100   \n",
       "max         251.200000  4254.000000          0.222600           1.058000   \n",
       "\n",
       "       worst concavity  worst concave points  worst symmetry  \\\n",
       "count       569.000000            569.000000      569.000000   \n",
       "mean          0.272188              0.114606        0.290076   \n",
       "std           0.208624              0.065732        0.061867   \n",
       "min           0.000000              0.000000        0.156500   \n",
       "25%           0.114500              0.064930        0.250400   \n",
       "50%           0.226700              0.099930        0.282200   \n",
       "75%           0.382900              0.161400        0.317900   \n",
       "max           1.252000              0.291000        0.663800   \n",
       "\n",
       "       worst fractal dimension      target  \n",
       "count               569.000000  569.000000  \n",
       "mean                  0.083946    0.627417  \n",
       "std                   0.018061    0.483918  \n",
       "min                   0.055040    0.000000  \n",
       "25%                   0.071460    0.000000  \n",
       "50%                   0.080040    1.000000  \n",
       "75%                   0.092080    1.000000  \n",
       "max                   0.207500    1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 415,
     "status": "ok",
     "timestamp": 1657211035332,
     "user": {
      "displayName": "Darshan Darshu",
      "userId": "08066444614316366436"
     },
     "user_tz": -330
    },
    "id": "6P4teME_lK7K"
   },
   "outputs": [],
   "source": [
    "x=df.iloc[:,:-1].values\n",
    "y=df.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 736,
     "status": "ok",
     "timestamp": 1657211039869,
     "user": {
      "displayName": "Darshan Darshu",
      "userId": "08066444614316366436"
     },
     "user_tz": -330
    },
    "id": "q28RGDCmlqcb",
    "outputId": "70c81a47-930c-482c-a448-8ac998c25235"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n",
       "        1.189e-01],\n",
       "       [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n",
       "        8.902e-02],\n",
       "       [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n",
       "        8.758e-02],\n",
       "       ...,\n",
       "       [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n",
       "        7.820e-02],\n",
       "       [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n",
       "        1.240e-01],\n",
       "       [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n",
       "        7.039e-02]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1657211043816,
     "user": {
      "displayName": "Darshan Darshu",
      "userId": "08066444614316366436"
     },
     "user_tz": -330
    },
    "id": "j7NmSgcMlrfx",
    "outputId": "f44ef5f0-2441-4702-ece9-81389c902486"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "       0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1657211046402,
     "user": {
      "displayName": "Darshan Darshu",
      "userId": "08066444614316366436"
     },
     "user_tz": -330
    },
    "id": "gvc4hxguluDC"
   },
   "outputs": [],
   "source": [
    "xtrain, xtest, ytrain, ytest=train_test_split(x,y,test_size=0.3,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 534,
     "status": "ok",
     "timestamp": 1657211050095,
     "user": {
      "displayName": "Darshan Darshu",
      "userId": "08066444614316366436"
     },
     "user_tz": -330
    },
    "id": "Ml70R92tmjQr"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc=StandardScaler()\n",
    "xtrain=sc.fit_transform(xtrain)\n",
    "xtest=sc.transform(xtest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 42805,
     "status": "ok",
     "timestamp": 1657211099362,
     "user": {
      "displayName": "Darshan Darshu",
      "userId": "08066444614316366436"
     },
     "user_tz": -330
    },
    "id": "jAH6eOeBn50H",
    "outputId": "089e3f75-fa90-42fc-c89f-d038e67ce1dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      "13/13 [==============================] - 1s 18ms/step - loss: 0.5898 - val_loss: 0.4818\n",
      "Epoch 2/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3918 - val_loss: 0.3503\n",
      "Epoch 3/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2815 - val_loss: 0.2763\n",
      "Epoch 4/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.2150 - val_loss: 0.2311\n",
      "Epoch 5/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1743 - val_loss: 0.1973\n",
      "Epoch 6/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1446 - val_loss: 0.1732\n",
      "Epoch 7/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1244 - val_loss: 0.1557\n",
      "Epoch 8/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1093 - val_loss: 0.1420\n",
      "Epoch 9/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0978 - val_loss: 0.1305\n",
      "Epoch 10/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0879 - val_loss: 0.1228\n",
      "Epoch 11/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0809 - val_loss: 0.1161\n",
      "Epoch 12/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0744 - val_loss: 0.1114\n",
      "Epoch 13/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0694 - val_loss: 0.1081\n",
      "Epoch 14/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0650 - val_loss: 0.1051\n",
      "Epoch 15/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0614 - val_loss: 0.1024\n",
      "Epoch 16/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0580 - val_loss: 0.1008\n",
      "Epoch 17/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0554 - val_loss: 0.0994\n",
      "Epoch 18/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0529 - val_loss: 0.0980\n",
      "Epoch 19/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0505 - val_loss: 0.0969\n",
      "Epoch 20/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0486 - val_loss: 0.0955\n",
      "Epoch 21/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0467 - val_loss: 0.0946\n",
      "Epoch 22/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0446 - val_loss: 0.0946\n",
      "Epoch 23/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0436 - val_loss: 0.0948\n",
      "Epoch 24/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0417 - val_loss: 0.0942\n",
      "Epoch 25/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0403 - val_loss: 0.0933\n",
      "Epoch 26/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0389 - val_loss: 0.0926\n",
      "Epoch 27/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0375 - val_loss: 0.0929\n",
      "Epoch 28/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0362 - val_loss: 0.0928\n",
      "Epoch 29/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0350 - val_loss: 0.0924\n",
      "Epoch 30/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0343 - val_loss: 0.0919\n",
      "Epoch 31/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0328 - val_loss: 0.0914\n",
      "Epoch 32/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0321 - val_loss: 0.0917\n",
      "Epoch 33/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0307 - val_loss: 0.0903\n",
      "Epoch 34/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0302 - val_loss: 0.0897\n",
      "Epoch 35/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0288 - val_loss: 0.0895\n",
      "Epoch 36/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0278 - val_loss: 0.0900\n",
      "Epoch 37/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0270 - val_loss: 0.0902\n",
      "Epoch 38/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0260 - val_loss: 0.0899\n",
      "Epoch 39/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0251 - val_loss: 0.0899\n",
      "Epoch 40/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0244 - val_loss: 0.0897\n",
      "Epoch 41/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0235 - val_loss: 0.0898\n",
      "Epoch 42/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0230 - val_loss: 0.0899\n",
      "Epoch 43/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0220 - val_loss: 0.0894\n",
      "Epoch 44/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0214 - val_loss: 0.0891\n",
      "Epoch 45/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0210 - val_loss: 0.0895\n",
      "Epoch 46/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0201 - val_loss: 0.0893\n",
      "Epoch 47/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0195 - val_loss: 0.0894\n",
      "Epoch 48/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0184 - val_loss: 0.0889\n",
      "Epoch 49/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0178 - val_loss: 0.0888\n",
      "Epoch 50/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0172 - val_loss: 0.0892\n",
      "Epoch 51/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0165 - val_loss: 0.0894\n",
      "Epoch 52/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0160 - val_loss: 0.0894\n",
      "Epoch 53/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0156 - val_loss: 0.0896\n",
      "Epoch 54/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0151 - val_loss: 0.0896\n",
      "Epoch 55/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0145 - val_loss: 0.0896\n",
      "Epoch 56/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0141 - val_loss: 0.0897\n",
      "Epoch 57/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0135 - val_loss: 0.0897\n",
      "Epoch 58/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0130 - val_loss: 0.0902\n",
      "Epoch 59/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0128 - val_loss: 0.0902\n",
      "Epoch 60/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0122 - val_loss: 0.0903\n",
      "Epoch 61/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0119 - val_loss: 0.0902\n",
      "Epoch 62/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0115 - val_loss: 0.0909\n",
      "Epoch 63/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0111 - val_loss: 0.0912\n",
      "Epoch 64/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0106 - val_loss: 0.0917\n",
      "Epoch 65/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0104 - val_loss: 0.0919\n",
      "Epoch 66/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0099 - val_loss: 0.0915\n",
      "Epoch 67/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0098 - val_loss: 0.0916\n",
      "Epoch 68/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0093 - val_loss: 0.0915\n",
      "Epoch 69/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0089 - val_loss: 0.0922\n",
      "Epoch 70/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0086 - val_loss: 0.0926\n",
      "Epoch 71/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0083 - val_loss: 0.0933\n",
      "Epoch 72/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0081 - val_loss: 0.0938\n",
      "Epoch 73/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0078 - val_loss: 0.0942\n",
      "Epoch 74/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0076 - val_loss: 0.0949\n",
      "Epoch 75/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0074 - val_loss: 0.0949\n",
      "Epoch 76/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0070 - val_loss: 0.0955\n",
      "Epoch 77/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0068 - val_loss: 0.0954\n",
      "Epoch 78/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0066 - val_loss: 0.0959\n",
      "Epoch 79/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0063 - val_loss: 0.0964\n",
      "Epoch 80/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0061 - val_loss: 0.0967\n",
      "Epoch 81/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0059 - val_loss: 0.0971\n",
      "Epoch 82/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0058 - val_loss: 0.0970\n",
      "Epoch 83/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0056 - val_loss: 0.0976\n",
      "Epoch 84/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0054 - val_loss: 0.0977\n",
      "Epoch 85/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0052 - val_loss: 0.0981\n",
      "Epoch 86/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0051 - val_loss: 0.0983\n",
      "Epoch 87/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0049 - val_loss: 0.0987\n",
      "Epoch 88/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0049 - val_loss: 0.0996\n",
      "Epoch 89/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0047 - val_loss: 0.1001\n",
      "Epoch 90/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.1006\n",
      "Epoch 91/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0045 - val_loss: 0.1009\n",
      "Epoch 92/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.1015\n",
      "Epoch 93/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.1022\n",
      "Epoch 94/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0041 - val_loss: 0.1020\n",
      "Epoch 95/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.1024\n",
      "Epoch 96/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.1026\n",
      "Epoch 97/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0038 - val_loss: 0.1031\n",
      "Epoch 98/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.1034\n",
      "Epoch 99/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.1035\n",
      "Epoch 100/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0035 - val_loss: 0.1042\n",
      "Epoch 101/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.1045\n",
      "Epoch 102/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0033 - val_loss: 0.1050\n",
      "Epoch 103/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0032 - val_loss: 0.1054\n",
      "Epoch 104/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0031 - val_loss: 0.1056\n",
      "Epoch 105/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0031 - val_loss: 0.1058\n",
      "Epoch 106/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0030 - val_loss: 0.1062\n",
      "Epoch 107/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0029 - val_loss: 0.1063\n",
      "Epoch 108/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0029 - val_loss: 0.1067\n",
      "Epoch 109/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0028 - val_loss: 0.1074\n",
      "Epoch 110/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0028 - val_loss: 0.1078\n",
      "Epoch 111/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0027 - val_loss: 0.1086\n",
      "Epoch 112/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0026 - val_loss: 0.1087\n",
      "Epoch 113/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0026 - val_loss: 0.1090\n",
      "Epoch 114/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0025 - val_loss: 0.1097\n",
      "Epoch 115/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0024 - val_loss: 0.1100\n",
      "Epoch 116/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0024 - val_loss: 0.1106\n",
      "Epoch 117/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0023 - val_loss: 0.1106\n",
      "Epoch 118/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0023 - val_loss: 0.1117\n",
      "Epoch 119/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.1119\n",
      "Epoch 120/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0021 - val_loss: 0.1122\n",
      "Epoch 121/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0021 - val_loss: 0.1124\n",
      "Epoch 122/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0021 - val_loss: 0.1128\n",
      "Epoch 123/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0020 - val_loss: 0.1132\n",
      "Epoch 124/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0020 - val_loss: 0.1133\n",
      "Epoch 125/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0019 - val_loss: 0.1137\n",
      "Epoch 126/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0019 - val_loss: 0.1139\n",
      "Epoch 127/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0019 - val_loss: 0.1142\n",
      "Epoch 128/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0018 - val_loss: 0.1145\n",
      "Epoch 129/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.1150\n",
      "Epoch 130/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0017 - val_loss: 0.1154\n",
      "Epoch 131/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.1158\n",
      "Epoch 132/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.1160\n",
      "Epoch 133/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0016 - val_loss: 0.1159\n",
      "Epoch 134/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0016 - val_loss: 0.1165\n",
      "Epoch 135/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0016 - val_loss: 0.1173\n",
      "Epoch 136/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0015 - val_loss: 0.1175\n",
      "Epoch 137/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0015 - val_loss: 0.1177\n",
      "Epoch 138/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0015 - val_loss: 0.1186\n",
      "Epoch 139/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0015 - val_loss: 0.1194\n",
      "Epoch 140/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.1194\n",
      "Epoch 141/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.1193\n",
      "Epoch 142/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0014 - val_loss: 0.1206\n",
      "Epoch 143/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.1210\n",
      "Epoch 144/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.1213\n",
      "Epoch 145/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.1215\n",
      "Epoch 146/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 0.1218\n",
      "Epoch 147/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.1225\n",
      "Epoch 148/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.1228\n",
      "Epoch 149/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.1233\n",
      "Epoch 150/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 0.1235\n",
      "Epoch 151/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.1239\n",
      "Epoch 152/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.1249\n",
      "Epoch 153/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 0.1253\n",
      "Epoch 154/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 0.1255\n",
      "Epoch 155/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 0.1261\n",
      "Epoch 156/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 0.1264\n",
      "Epoch 157/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 9.9570e-04 - val_loss: 0.1268\n",
      "Epoch 158/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 9.7473e-04 - val_loss: 0.1272\n",
      "Epoch 159/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 9.5031e-04 - val_loss: 0.1277\n",
      "Epoch 160/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 9.3376e-04 - val_loss: 0.1279\n",
      "Epoch 161/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 9.1386e-04 - val_loss: 0.1281\n",
      "Epoch 162/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 8.9978e-04 - val_loss: 0.1287\n",
      "Epoch 163/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 8.7645e-04 - val_loss: 0.1288\n",
      "Epoch 164/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 8.7593e-04 - val_loss: 0.1287\n",
      "Epoch 165/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 8.5850e-04 - val_loss: 0.1298\n",
      "Epoch 166/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 8.3103e-04 - val_loss: 0.1301\n",
      "Epoch 167/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 8.1468e-04 - val_loss: 0.1304\n",
      "Epoch 168/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 8.0112e-04 - val_loss: 0.1307\n",
      "Epoch 169/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 7.8578e-04 - val_loss: 0.1308\n",
      "Epoch 170/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 7.6672e-04 - val_loss: 0.1314\n",
      "Epoch 171/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 7.6446e-04 - val_loss: 0.1317\n",
      "Epoch 172/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 7.4820e-04 - val_loss: 0.1320\n",
      "Epoch 173/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 7.3971e-04 - val_loss: 0.1325\n",
      "Epoch 174/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 7.1837e-04 - val_loss: 0.1329\n",
      "Epoch 175/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 6.9902e-04 - val_loss: 0.1332\n",
      "Epoch 176/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 6.9604e-04 - val_loss: 0.1336\n",
      "Epoch 177/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 6.7529e-04 - val_loss: 0.1339\n",
      "Epoch 178/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 6.6506e-04 - val_loss: 0.1342\n",
      "Epoch 179/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 6.5161e-04 - val_loss: 0.1349\n",
      "Epoch 180/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 6.4431e-04 - val_loss: 0.1351\n",
      "Epoch 181/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 6.3190e-04 - val_loss: 0.1350\n",
      "Epoch 182/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 6.1973e-04 - val_loss: 0.1356\n",
      "Epoch 183/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 6.1512e-04 - val_loss: 0.1361\n",
      "Epoch 184/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 5.9272e-04 - val_loss: 0.1360\n",
      "Epoch 185/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 5.9098e-04 - val_loss: 0.1362\n",
      "Epoch 186/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 5.8015e-04 - val_loss: 0.1365\n",
      "Epoch 187/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 5.6755e-04 - val_loss: 0.1370\n",
      "Epoch 188/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 5.6323e-04 - val_loss: 0.1383\n",
      "Epoch 189/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 5.5631e-04 - val_loss: 0.1385\n",
      "Epoch 190/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 5.4669e-04 - val_loss: 0.1385\n",
      "Epoch 191/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 5.3985e-04 - val_loss: 0.1386\n",
      "Epoch 192/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 5.2788e-04 - val_loss: 0.1389\n",
      "Epoch 193/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 5.1537e-04 - val_loss: 0.1393\n",
      "Epoch 194/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 5.0715e-04 - val_loss: 0.1398\n",
      "Epoch 195/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 4.9876e-04 - val_loss: 0.1398\n",
      "Epoch 196/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4.8610e-04 - val_loss: 0.1404\n",
      "Epoch 197/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 4.8032e-04 - val_loss: 0.1406\n",
      "Epoch 198/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4.6653e-04 - val_loss: 0.1416\n",
      "Epoch 199/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4.6552e-04 - val_loss: 0.1421\n",
      "Epoch 200/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4.5638e-04 - val_loss: 0.1422\n",
      "Epoch 201/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 4.4760e-04 - val_loss: 0.1424\n",
      "Epoch 202/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4.5388e-04 - val_loss: 0.1426\n",
      "Epoch 203/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4.3613e-04 - val_loss: 0.1429\n",
      "Epoch 204/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4.3475e-04 - val_loss: 0.1435\n",
      "Epoch 205/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4.2140e-04 - val_loss: 0.1439\n",
      "Epoch 206/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4.1620e-04 - val_loss: 0.1441\n",
      "Epoch 207/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4.0578e-04 - val_loss: 0.1445\n",
      "Epoch 208/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 4.0097e-04 - val_loss: 0.1447\n",
      "Epoch 209/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.9372e-04 - val_loss: 0.1451\n",
      "Epoch 210/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 3.8786e-04 - val_loss: 0.1456\n",
      "Epoch 211/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 3.8146e-04 - val_loss: 0.1460\n",
      "Epoch 212/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.7854e-04 - val_loss: 0.1462\n",
      "Epoch 213/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.7114e-04 - val_loss: 0.1466\n",
      "Epoch 214/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 3.6697e-04 - val_loss: 0.1469\n",
      "Epoch 215/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 3.5908e-04 - val_loss: 0.1471\n",
      "Epoch 216/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 3.5679e-04 - val_loss: 0.1473\n",
      "Epoch 217/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 3.5013e-04 - val_loss: 0.1478\n",
      "Epoch 218/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 3.4620e-04 - val_loss: 0.1480\n",
      "Epoch 219/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.4009e-04 - val_loss: 0.1483\n",
      "Epoch 220/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.3671e-04 - val_loss: 0.1486\n",
      "Epoch 221/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.3198e-04 - val_loss: 0.1489\n",
      "Epoch 222/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.3222e-04 - val_loss: 0.1496\n",
      "Epoch 223/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 3.2346e-04 - val_loss: 0.1497\n",
      "Epoch 224/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.1709e-04 - val_loss: 0.1501\n",
      "Epoch 225/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 3.1033e-04 - val_loss: 0.1503\n",
      "Epoch 226/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.0688e-04 - val_loss: 0.1507\n",
      "Epoch 227/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 3.0244e-04 - val_loss: 0.1508\n",
      "Epoch 228/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.9782e-04 - val_loss: 0.1512\n",
      "Epoch 229/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.9371e-04 - val_loss: 0.1515\n",
      "Epoch 230/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.8813e-04 - val_loss: 0.1516\n",
      "Epoch 231/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.8650e-04 - val_loss: 0.1519\n",
      "Epoch 232/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.8206e-04 - val_loss: 0.1522\n",
      "Epoch 233/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.7756e-04 - val_loss: 0.1527\n",
      "Epoch 234/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.7641e-04 - val_loss: 0.1531\n",
      "Epoch 235/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.7016e-04 - val_loss: 0.1536\n",
      "Epoch 236/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.6744e-04 - val_loss: 0.1537\n",
      "Epoch 237/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.6364e-04 - val_loss: 0.1539\n",
      "Epoch 238/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.6100e-04 - val_loss: 0.1543\n",
      "Epoch 239/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.5935e-04 - val_loss: 0.1545\n",
      "Epoch 240/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.5306e-04 - val_loss: 0.1556\n",
      "Epoch 241/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.5020e-04 - val_loss: 0.1558\n",
      "Epoch 242/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.4562e-04 - val_loss: 0.1559\n",
      "Epoch 243/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.4506e-04 - val_loss: 0.1561\n",
      "Epoch 244/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.4167e-04 - val_loss: 0.1569\n",
      "Epoch 245/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.3810e-04 - val_loss: 0.1569\n",
      "Epoch 246/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.3402e-04 - val_loss: 0.1572\n",
      "Epoch 247/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.3092e-04 - val_loss: 0.1575\n",
      "Epoch 248/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.2828e-04 - val_loss: 0.1576\n",
      "Epoch 249/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.2703e-04 - val_loss: 0.1588\n",
      "Epoch 250/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.2453e-04 - val_loss: 0.1586\n",
      "Epoch 251/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.2024e-04 - val_loss: 0.1589\n",
      "Epoch 252/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.1617e-04 - val_loss: 0.1591\n",
      "Epoch 253/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.1678e-04 - val_loss: 0.1599\n",
      "Epoch 254/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.1284e-04 - val_loss: 0.1601\n",
      "Epoch 255/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.0765e-04 - val_loss: 0.1602\n",
      "Epoch 256/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.0844e-04 - val_loss: 0.1604\n",
      "Epoch 257/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.0358e-04 - val_loss: 0.1608\n",
      "Epoch 258/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.0026e-04 - val_loss: 0.1610\n",
      "Epoch 259/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.9806e-04 - val_loss: 0.1612\n",
      "Epoch 260/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.9676e-04 - val_loss: 0.1615\n",
      "Epoch 261/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.9391e-04 - val_loss: 0.1618\n",
      "Epoch 262/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.9146e-04 - val_loss: 0.1620\n",
      "Epoch 263/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.8931e-04 - val_loss: 0.1623\n",
      "Epoch 264/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.8706e-04 - val_loss: 0.1627\n",
      "Epoch 265/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.8419e-04 - val_loss: 0.1630\n",
      "Epoch 266/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.8202e-04 - val_loss: 0.1631\n",
      "Epoch 267/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.7969e-04 - val_loss: 0.1635\n",
      "Epoch 268/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.7736e-04 - val_loss: 0.1638\n",
      "Epoch 269/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.7543e-04 - val_loss: 0.1642\n",
      "Epoch 270/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.7318e-04 - val_loss: 0.1644\n",
      "Epoch 271/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.7242e-04 - val_loss: 0.1648\n",
      "Epoch 272/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.6890e-04 - val_loss: 0.1649\n",
      "Epoch 273/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.6783e-04 - val_loss: 0.1650\n",
      "Epoch 274/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.6501e-04 - val_loss: 0.1655\n",
      "Epoch 275/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.6243e-04 - val_loss: 0.1658\n",
      "Epoch 276/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.6202e-04 - val_loss: 0.1660\n",
      "Epoch 277/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.5882e-04 - val_loss: 0.1664\n",
      "Epoch 278/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.5678e-04 - val_loss: 0.1664\n",
      "Epoch 279/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.5481e-04 - val_loss: 0.1667\n",
      "Epoch 280/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.5689e-04 - val_loss: 0.1671\n",
      "Epoch 281/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.5099e-04 - val_loss: 0.1676\n",
      "Epoch 282/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.5083e-04 - val_loss: 0.1679\n",
      "Epoch 283/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.4802e-04 - val_loss: 0.1681\n",
      "Epoch 284/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.4579e-04 - val_loss: 0.1682\n",
      "Epoch 285/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.4592e-04 - val_loss: 0.1684\n",
      "Epoch 286/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.4375e-04 - val_loss: 0.1688\n",
      "Epoch 287/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.4071e-04 - val_loss: 0.1689\n",
      "Epoch 288/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.3985e-04 - val_loss: 0.1695\n",
      "Epoch 289/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.3818e-04 - val_loss: 0.1700\n",
      "Epoch 290/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.3501e-04 - val_loss: 0.1702\n",
      "Epoch 291/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.3515e-04 - val_loss: 0.1701\n",
      "Epoch 292/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.3343e-04 - val_loss: 0.1707\n",
      "Epoch 293/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.3179e-04 - val_loss: 0.1711\n",
      "Epoch 294/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.3000e-04 - val_loss: 0.1712\n",
      "Epoch 295/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.2878e-04 - val_loss: 0.1713\n",
      "Epoch 296/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.2704e-04 - val_loss: 0.1716\n",
      "Epoch 297/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.2544e-04 - val_loss: 0.1719\n",
      "Epoch 298/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.2477e-04 - val_loss: 0.1721\n",
      "Epoch 299/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.2303e-04 - val_loss: 0.1725\n",
      "Epoch 300/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.2135e-04 - val_loss: 0.1728\n",
      "Epoch 301/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.1955e-04 - val_loss: 0.1728\n",
      "Epoch 302/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.1884e-04 - val_loss: 0.1734\n",
      "Epoch 303/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.1716e-04 - val_loss: 0.1737\n",
      "Epoch 304/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.1677e-04 - val_loss: 0.1738\n",
      "Epoch 305/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.1534e-04 - val_loss: 0.1742\n",
      "Epoch 306/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.1391e-04 - val_loss: 0.1746\n",
      "Epoch 307/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.1229e-04 - val_loss: 0.1744\n",
      "Epoch 308/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.1159e-04 - val_loss: 0.1746\n",
      "Epoch 309/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.1096e-04 - val_loss: 0.1751\n",
      "Epoch 310/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.0987e-04 - val_loss: 0.1751\n",
      "Epoch 311/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.0722e-04 - val_loss: 0.1759\n",
      "Epoch 312/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.0651e-04 - val_loss: 0.1762\n",
      "Epoch 313/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.0568e-04 - val_loss: 0.1764\n",
      "Epoch 314/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.0448e-04 - val_loss: 0.1764\n",
      "Epoch 315/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.0249e-04 - val_loss: 0.1768\n",
      "Epoch 316/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.0158e-04 - val_loss: 0.1773\n",
      "Epoch 317/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.0223e-04 - val_loss: 0.1773\n",
      "Epoch 318/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.0050e-04 - val_loss: 0.1776\n",
      "Epoch 319/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 9.8906e-05 - val_loss: 0.1779\n",
      "Epoch 320/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 9.7411e-05 - val_loss: 0.1781\n",
      "Epoch 321/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 9.6297e-05 - val_loss: 0.1784\n",
      "Epoch 322/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 9.5621e-05 - val_loss: 0.1784\n",
      "Epoch 323/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 9.4188e-05 - val_loss: 0.1790\n",
      "Epoch 324/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 9.3215e-05 - val_loss: 0.1791\n",
      "Epoch 325/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 9.3436e-05 - val_loss: 0.1792\n",
      "Epoch 326/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 9.1239e-05 - val_loss: 0.1797\n",
      "Epoch 327/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 9.0175e-05 - val_loss: 0.1800\n",
      "Epoch 328/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 8.9899e-05 - val_loss: 0.1803\n",
      "Epoch 329/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 8.8515e-05 - val_loss: 0.1805\n",
      "Epoch 330/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 8.7965e-05 - val_loss: 0.1808\n",
      "Epoch 331/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 8.7036e-05 - val_loss: 0.1810\n",
      "Epoch 332/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 8.6700e-05 - val_loss: 0.1819\n",
      "Epoch 333/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 8.5325e-05 - val_loss: 0.1820\n",
      "Epoch 334/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 8.4460e-05 - val_loss: 0.1823\n",
      "Epoch 335/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 8.3319e-05 - val_loss: 0.1828\n",
      "Epoch 336/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 8.2809e-05 - val_loss: 0.1826\n",
      "Epoch 337/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 8.1231e-05 - val_loss: 0.1829\n",
      "Epoch 338/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 8.0748e-05 - val_loss: 0.1831\n",
      "Epoch 339/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 7.9484e-05 - val_loss: 0.1835\n",
      "Epoch 340/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 7.9198e-05 - val_loss: 0.1836\n",
      "Epoch 341/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 7.8162e-05 - val_loss: 0.1838\n",
      "Epoch 342/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 7.8056e-05 - val_loss: 0.1841\n",
      "Epoch 343/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 7.6660e-05 - val_loss: 0.1841\n",
      "Epoch 344/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 7.5999e-05 - val_loss: 0.1842\n",
      "Epoch 345/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 7.5172e-05 - val_loss: 0.1847\n",
      "Epoch 346/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 7.4841e-05 - val_loss: 0.1848\n",
      "Epoch 347/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 7.3303e-05 - val_loss: 0.1851\n",
      "Epoch 348/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 7.2895e-05 - val_loss: 0.1853\n",
      "Epoch 349/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 7.2360e-05 - val_loss: 0.1856\n",
      "Epoch 350/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 7.1824e-05 - val_loss: 0.1859\n",
      "Epoch 351/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 7.1027e-05 - val_loss: 0.1859\n",
      "Epoch 352/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 7.0222e-05 - val_loss: 0.1863\n",
      "Epoch 353/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 6.9809e-05 - val_loss: 0.1866\n",
      "Epoch 354/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 6.8487e-05 - val_loss: 0.1867\n",
      "Epoch 355/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 6.7962e-05 - val_loss: 0.1870\n",
      "Epoch 356/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 6.7482e-05 - val_loss: 0.1871\n",
      "Epoch 357/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 6.7313e-05 - val_loss: 0.1876\n",
      "Epoch 358/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 6.5979e-05 - val_loss: 0.1877\n",
      "Epoch 359/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 6.5529e-05 - val_loss: 0.1878\n",
      "Epoch 360/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 6.5311e-05 - val_loss: 0.1882\n",
      "Epoch 361/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 6.4353e-05 - val_loss: 0.1885\n",
      "Epoch 362/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 6.3742e-05 - val_loss: 0.1886\n",
      "Epoch 363/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 6.2947e-05 - val_loss: 0.1889\n",
      "Epoch 364/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 6.2079e-05 - val_loss: 0.1891\n",
      "Epoch 365/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 6.1938e-05 - val_loss: 0.1895\n",
      "Epoch 366/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 6.1044e-05 - val_loss: 0.1897\n",
      "Epoch 367/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 6.0599e-05 - val_loss: 0.1899\n",
      "Epoch 368/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 6.0299e-05 - val_loss: 0.1902\n",
      "Epoch 369/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 5.9422e-05 - val_loss: 0.1906\n",
      "Epoch 370/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 5.8798e-05 - val_loss: 0.1909\n",
      "Epoch 371/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 5.8622e-05 - val_loss: 0.1909\n",
      "Epoch 372/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 5.8485e-05 - val_loss: 0.1918\n",
      "Epoch 373/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 5.7363e-05 - val_loss: 0.1921\n",
      "Epoch 374/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 5.6703e-05 - val_loss: 0.1920\n",
      "Epoch 375/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 5.6035e-05 - val_loss: 0.1923\n",
      "Epoch 376/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 5.5385e-05 - val_loss: 0.1925\n",
      "Epoch 377/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 5.5126e-05 - val_loss: 0.1926\n",
      "Epoch 378/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 5.4700e-05 - val_loss: 0.1930\n",
      "Epoch 379/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 5.3901e-05 - val_loss: 0.1931\n",
      "Epoch 380/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 5.3542e-05 - val_loss: 0.1931\n",
      "Epoch 381/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 5.3056e-05 - val_loss: 0.1934\n",
      "Epoch 382/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 5.2421e-05 - val_loss: 0.1936\n",
      "Epoch 383/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 5.2462e-05 - val_loss: 0.1939\n",
      "Epoch 384/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 5.1638e-05 - val_loss: 0.1940\n",
      "Epoch 385/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 5.1355e-05 - val_loss: 0.1947\n",
      "Epoch 386/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 5.0593e-05 - val_loss: 0.1948\n",
      "Epoch 387/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 5.0282e-05 - val_loss: 0.1951\n",
      "Epoch 388/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4.9429e-05 - val_loss: 0.1952\n",
      "Epoch 389/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 4.8848e-05 - val_loss: 0.1956\n",
      "Epoch 390/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 4.8738e-05 - val_loss: 0.1960\n",
      "Epoch 391/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4.8282e-05 - val_loss: 0.1960\n",
      "Epoch 392/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4.8184e-05 - val_loss: 0.1964\n",
      "Epoch 393/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 4.7722e-05 - val_loss: 0.1967\n",
      "Epoch 394/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.6673e-05 - val_loss: 0.1970\n",
      "Epoch 395/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4.6446e-05 - val_loss: 0.1971\n",
      "Epoch 396/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 4.5804e-05 - val_loss: 0.1975\n",
      "Epoch 397/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 4.5505e-05 - val_loss: 0.1977\n",
      "Epoch 398/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 4.5266e-05 - val_loss: 0.1979\n",
      "Epoch 399/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 4.5063e-05 - val_loss: 0.1980\n",
      "Epoch 400/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 4.4226e-05 - val_loss: 0.1983\n",
      "Epoch 401/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3747e-05 - val_loss: 0.1987\n",
      "Epoch 402/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 4.3513e-05 - val_loss: 0.1988\n",
      "Epoch 403/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4.3075e-05 - val_loss: 0.1994\n",
      "Epoch 404/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 4.2559e-05 - val_loss: 0.1995\n",
      "Epoch 405/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 4.2309e-05 - val_loss: 0.1996\n",
      "Epoch 406/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 4.1723e-05 - val_loss: 0.1998\n",
      "Epoch 407/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4.1297e-05 - val_loss: 0.2002\n",
      "Epoch 408/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4.1171e-05 - val_loss: 0.2004\n",
      "Epoch 409/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 4.0672e-05 - val_loss: 0.2010\n",
      "Epoch 410/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4.0352e-05 - val_loss: 0.2009\n",
      "Epoch 411/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 3.9736e-05 - val_loss: 0.2013\n",
      "Epoch 412/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 3.9518e-05 - val_loss: 0.2015\n",
      "Epoch 413/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 3.9058e-05 - val_loss: 0.2018\n",
      "Epoch 414/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.9102e-05 - val_loss: 0.2018\n",
      "Epoch 415/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 3.8466e-05 - val_loss: 0.2018\n",
      "Epoch 416/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 3.8274e-05 - val_loss: 0.2022\n",
      "Epoch 417/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 3.7947e-05 - val_loss: 0.2025\n",
      "Epoch 418/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 3.7301e-05 - val_loss: 0.2029\n",
      "Epoch 419/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.6981e-05 - val_loss: 0.2035\n",
      "Epoch 420/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.6527e-05 - val_loss: 0.2036\n",
      "Epoch 421/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.6230e-05 - val_loss: 0.2038\n",
      "Epoch 422/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 3.5762e-05 - val_loss: 0.2041\n",
      "Epoch 423/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 3.5896e-05 - val_loss: 0.2042\n",
      "Epoch 424/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 3.5397e-05 - val_loss: 0.2043\n",
      "Epoch 425/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 3.5291e-05 - val_loss: 0.2046\n",
      "Epoch 426/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 3.4887e-05 - val_loss: 0.2047\n",
      "Epoch 427/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.4466e-05 - val_loss: 0.2053\n",
      "Epoch 428/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 3.4088e-05 - val_loss: 0.2054\n",
      "Epoch 429/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.3836e-05 - val_loss: 0.2053\n",
      "Epoch 430/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.3371e-05 - val_loss: 0.2060\n",
      "Epoch 431/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 3.3349e-05 - val_loss: 0.2064\n",
      "Epoch 432/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.2672e-05 - val_loss: 0.2064\n",
      "Epoch 433/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 3.2302e-05 - val_loss: 0.2068\n",
      "Epoch 434/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.1931e-05 - val_loss: 0.2067\n",
      "Epoch 435/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 3.1766e-05 - val_loss: 0.2070\n",
      "Epoch 436/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.1499e-05 - val_loss: 0.2074\n",
      "Epoch 437/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 3.1233e-05 - val_loss: 0.2074\n",
      "Epoch 438/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 3.1250e-05 - val_loss: 0.2074\n",
      "Epoch 439/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 3.0608e-05 - val_loss: 0.2079\n",
      "Epoch 440/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 3.0525e-05 - val_loss: 0.2083\n",
      "Epoch 441/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.0042e-05 - val_loss: 0.2084\n",
      "Epoch 442/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.9917e-05 - val_loss: 0.2085\n",
      "Epoch 443/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.9540e-05 - val_loss: 0.2088\n",
      "Epoch 444/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.9246e-05 - val_loss: 0.2091\n",
      "Epoch 445/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.9076e-05 - val_loss: 0.2092\n",
      "Epoch 446/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.8800e-05 - val_loss: 0.2093\n",
      "Epoch 447/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.8702e-05 - val_loss: 0.2097\n",
      "Epoch 448/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.8206e-05 - val_loss: 0.2098\n",
      "Epoch 449/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.8162e-05 - val_loss: 0.2100\n",
      "Epoch 450/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.7873e-05 - val_loss: 0.2102\n",
      "Epoch 451/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.7618e-05 - val_loss: 0.2110\n",
      "Epoch 452/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.7489e-05 - val_loss: 0.2111\n",
      "Epoch 453/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.7068e-05 - val_loss: 0.2113\n",
      "Epoch 454/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.6905e-05 - val_loss: 0.2113\n",
      "Epoch 455/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.6862e-05 - val_loss: 0.2119\n",
      "Epoch 456/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.6326e-05 - val_loss: 0.2119\n",
      "Epoch 457/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.6119e-05 - val_loss: 0.2121\n",
      "Epoch 458/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.5894e-05 - val_loss: 0.2124\n",
      "Epoch 459/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.5589e-05 - val_loss: 0.2126\n",
      "Epoch 460/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.5457e-05 - val_loss: 0.2129\n",
      "Epoch 461/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.5144e-05 - val_loss: 0.2131\n",
      "Epoch 462/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.5156e-05 - val_loss: 0.2135\n",
      "Epoch 463/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.4715e-05 - val_loss: 0.2136\n",
      "Epoch 464/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.4824e-05 - val_loss: 0.2137\n",
      "Epoch 465/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.4546e-05 - val_loss: 0.2140\n",
      "Epoch 466/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.4268e-05 - val_loss: 0.2141\n",
      "Epoch 467/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.3943e-05 - val_loss: 0.2144\n",
      "Epoch 468/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.3724e-05 - val_loss: 0.2148\n",
      "Epoch 469/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.3551e-05 - val_loss: 0.2148\n",
      "Epoch 470/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.3249e-05 - val_loss: 0.2150\n",
      "Epoch 471/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.3275e-05 - val_loss: 0.2153\n",
      "Epoch 472/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.2993e-05 - val_loss: 0.2151\n",
      "Epoch 473/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.3046e-05 - val_loss: 0.2155\n",
      "Epoch 474/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.2623e-05 - val_loss: 0.2156\n",
      "Epoch 475/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.2339e-05 - val_loss: 0.2161\n",
      "Epoch 476/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.2171e-05 - val_loss: 0.2162\n",
      "Epoch 477/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.1894e-05 - val_loss: 0.2167\n",
      "Epoch 478/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.1676e-05 - val_loss: 0.2170\n",
      "Epoch 479/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.1446e-05 - val_loss: 0.2171\n",
      "Epoch 480/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.1273e-05 - val_loss: 0.2173\n",
      "Epoch 481/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.1222e-05 - val_loss: 0.2173\n",
      "Epoch 482/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.1251e-05 - val_loss: 0.2182\n",
      "Epoch 483/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.0887e-05 - val_loss: 0.2184\n",
      "Epoch 484/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.0637e-05 - val_loss: 0.2184\n",
      "Epoch 485/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.0415e-05 - val_loss: 0.2185\n",
      "Epoch 486/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.0387e-05 - val_loss: 0.2189\n",
      "Epoch 487/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.0057e-05 - val_loss: 0.2190\n",
      "Epoch 488/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.9930e-05 - val_loss: 0.2193\n",
      "Epoch 489/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.9776e-05 - val_loss: 0.2194\n",
      "Epoch 490/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.9560e-05 - val_loss: 0.2198\n",
      "Epoch 491/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.9473e-05 - val_loss: 0.2201\n",
      "Epoch 492/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.9251e-05 - val_loss: 0.2203\n",
      "Epoch 493/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.9079e-05 - val_loss: 0.2205\n",
      "Epoch 494/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.8931e-05 - val_loss: 0.2207\n",
      "Epoch 495/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.8819e-05 - val_loss: 0.2209\n",
      "Epoch 496/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.8647e-05 - val_loss: 0.2209\n",
      "Epoch 497/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.8456e-05 - val_loss: 0.2211\n",
      "Epoch 498/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.8351e-05 - val_loss: 0.2215\n",
      "Epoch 499/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.8156e-05 - val_loss: 0.2217\n",
      "Epoch 500/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.8041e-05 - val_loss: 0.2219\n",
      "Epoch 501/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.7945e-05 - val_loss: 0.2221\n",
      "Epoch 502/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.7755e-05 - val_loss: 0.2225\n",
      "Epoch 503/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.7783e-05 - val_loss: 0.2228\n",
      "Epoch 504/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.7449e-05 - val_loss: 0.2229\n",
      "Epoch 505/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.7237e-05 - val_loss: 0.2230\n",
      "Epoch 506/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.7140e-05 - val_loss: 0.2233\n",
      "Epoch 507/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.7052e-05 - val_loss: 0.2234\n",
      "Epoch 508/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.6846e-05 - val_loss: 0.2237\n",
      "Epoch 509/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.6685e-05 - val_loss: 0.2238\n",
      "Epoch 510/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.6583e-05 - val_loss: 0.2242\n",
      "Epoch 511/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.6560e-05 - val_loss: 0.2245\n",
      "Epoch 512/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.6334e-05 - val_loss: 0.2245\n",
      "Epoch 513/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.6311e-05 - val_loss: 0.2246\n",
      "Epoch 514/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.5940e-05 - val_loss: 0.2249\n",
      "Epoch 515/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.6066e-05 - val_loss: 0.2251\n",
      "Epoch 516/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.5857e-05 - val_loss: 0.2253\n",
      "Epoch 517/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.5644e-05 - val_loss: 0.2256\n",
      "Epoch 518/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.5527e-05 - val_loss: 0.2257\n",
      "Epoch 519/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.5316e-05 - val_loss: 0.2260\n",
      "Epoch 520/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.5273e-05 - val_loss: 0.2264\n",
      "Epoch 521/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.5113e-05 - val_loss: 0.2265\n",
      "Epoch 522/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.4999e-05 - val_loss: 0.2268\n",
      "Epoch 523/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.4779e-05 - val_loss: 0.2272\n",
      "Epoch 524/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.4631e-05 - val_loss: 0.2274\n",
      "Epoch 525/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.4579e-05 - val_loss: 0.2276\n",
      "Epoch 526/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.4480e-05 - val_loss: 0.2279\n",
      "Epoch 527/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.4346e-05 - val_loss: 0.2281\n",
      "Epoch 528/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.4245e-05 - val_loss: 0.2281\n",
      "Epoch 529/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.4158e-05 - val_loss: 0.2289\n",
      "Epoch 530/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.4033e-05 - val_loss: 0.2289\n",
      "Epoch 531/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.3826e-05 - val_loss: 0.2294\n",
      "Epoch 532/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.3772e-05 - val_loss: 0.2297\n",
      "Epoch 533/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.3631e-05 - val_loss: 0.2298\n",
      "Epoch 534/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.3462e-05 - val_loss: 0.2299\n",
      "Epoch 535/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.3497e-05 - val_loss: 0.2302\n",
      "Epoch 536/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.3251e-05 - val_loss: 0.2304\n",
      "Epoch 537/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.3319e-05 - val_loss: 0.2304\n",
      "Epoch 538/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.3120e-05 - val_loss: 0.2308\n",
      "Epoch 539/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.2961e-05 - val_loss: 0.2311\n",
      "Epoch 540/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.2872e-05 - val_loss: 0.2314\n",
      "Epoch 541/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.2734e-05 - val_loss: 0.2313\n",
      "Epoch 542/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.2621e-05 - val_loss: 0.2316\n",
      "Epoch 543/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.2517e-05 - val_loss: 0.2320\n",
      "Epoch 544/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.2423e-05 - val_loss: 0.2322\n",
      "Epoch 545/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.2364e-05 - val_loss: 0.2321\n",
      "Epoch 546/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.2220e-05 - val_loss: 0.2323\n",
      "Epoch 547/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.2214e-05 - val_loss: 0.2328\n",
      "Epoch 548/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.1963e-05 - val_loss: 0.2329\n",
      "Epoch 549/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.1886e-05 - val_loss: 0.2332\n",
      "Epoch 550/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.1839e-05 - val_loss: 0.2331\n",
      "Epoch 551/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.1690e-05 - val_loss: 0.2336\n",
      "Epoch 552/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.1652e-05 - val_loss: 0.2336\n",
      "Epoch 553/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.1491e-05 - val_loss: 0.2340\n",
      "Epoch 554/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.1471e-05 - val_loss: 0.2342\n",
      "Epoch 555/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.1466e-05 - val_loss: 0.2346\n",
      "Epoch 556/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.1265e-05 - val_loss: 0.2346\n",
      "Epoch 557/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.1239e-05 - val_loss: 0.2349\n",
      "Epoch 558/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.1115e-05 - val_loss: 0.2351\n",
      "Epoch 559/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.1097e-05 - val_loss: 0.2352\n",
      "Epoch 560/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.0986e-05 - val_loss: 0.2355\n",
      "Epoch 561/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.0790e-05 - val_loss: 0.2359\n",
      "Epoch 562/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.0731e-05 - val_loss: 0.2361\n",
      "Epoch 563/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.0572e-05 - val_loss: 0.2363\n",
      "Epoch 564/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.0554e-05 - val_loss: 0.2366\n",
      "Epoch 565/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.0444e-05 - val_loss: 0.2367\n",
      "Epoch 566/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.0390e-05 - val_loss: 0.2371\n",
      "Epoch 567/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.0245e-05 - val_loss: 0.2372\n",
      "Epoch 568/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.0197e-05 - val_loss: 0.2373\n",
      "Epoch 569/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.0161e-05 - val_loss: 0.2378\n",
      "Epoch 570/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 9.9901e-06 - val_loss: 0.2380\n",
      "Epoch 571/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 9.9588e-06 - val_loss: 0.2382\n",
      "Epoch 572/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 9.8122e-06 - val_loss: 0.2385\n",
      "Epoch 573/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 9.7382e-06 - val_loss: 0.2385\n",
      "Epoch 574/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 9.6707e-06 - val_loss: 0.2389\n",
      "Epoch 575/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 9.5623e-06 - val_loss: 0.2391\n",
      "Epoch 576/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 9.5267e-06 - val_loss: 0.2391\n",
      "Epoch 577/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 9.4128e-06 - val_loss: 0.2394\n",
      "Epoch 578/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 9.3637e-06 - val_loss: 0.2396\n",
      "Epoch 579/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 9.2897e-06 - val_loss: 0.2397\n",
      "Epoch 580/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 9.2293e-06 - val_loss: 0.2401\n",
      "Epoch 581/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 9.1180e-06 - val_loss: 0.2402\n",
      "Epoch 582/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 9.0901e-06 - val_loss: 0.2405\n",
      "Epoch 583/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 8.9847e-06 - val_loss: 0.2406\n",
      "Epoch 584/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 8.9538e-06 - val_loss: 0.2411\n",
      "Epoch 585/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 8.8851e-06 - val_loss: 0.2412\n",
      "Epoch 586/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 8.7764e-06 - val_loss: 0.2414\n",
      "Epoch 587/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 8.7376e-06 - val_loss: 0.2417\n",
      "Epoch 588/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 8.7000e-06 - val_loss: 0.2418\n",
      "Epoch 589/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 8.5904e-06 - val_loss: 0.2420\n",
      "Epoch 590/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 8.5430e-06 - val_loss: 0.2421\n",
      "Epoch 591/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 8.4048e-06 - val_loss: 0.2425\n",
      "Epoch 592/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 8.4087e-06 - val_loss: 0.2430\n",
      "Epoch 593/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 8.3367e-06 - val_loss: 0.2430\n",
      "Epoch 594/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 8.2342e-06 - val_loss: 0.2432\n",
      "Epoch 595/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 8.2426e-06 - val_loss: 0.2431\n",
      "Epoch 596/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 8.1005e-06 - val_loss: 0.2436\n",
      "Epoch 597/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 8.0340e-06 - val_loss: 0.2440\n",
      "Epoch 598/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 7.9747e-06 - val_loss: 0.2440\n",
      "Epoch 599/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 7.9163e-06 - val_loss: 0.2444\n",
      "Epoch 600/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 7.8702e-06 - val_loss: 0.2446\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f267f5fd310>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=Sequential()\n",
    "\n",
    "model.add(Dense(units=30,activation=\"relu\"))\n",
    "model.add(Dense(units=15,activation=\"relu\"))\n",
    "\n",
    "model.add(Dense(units=1,activation=\"sigmoid\"))\n",
    "\n",
    "model.compile(optimizer=\"adam\",loss=\"binary_crossentropy\")\n",
    "\n",
    "model.fit(xtrain,ytrain,epochs=600,validation_data=(xtest,ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 42,
     "status": "ok",
     "timestamp": 1657211099363,
     "user": {
      "displayName": "Darshan Darshu",
      "userId": "08066444614316366436"
     },
     "user_tz": -330
    },
    "id": "xLiP8L-Zp_c4",
    "outputId": "a0d782fa-afbf-47ad-f206-c466227892b1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.5898066163063049,\n",
       "  0.3918284773826599,\n",
       "  0.28147807717323303,\n",
       "  0.21498920023441315,\n",
       "  0.1743127405643463,\n",
       "  0.1446470469236374,\n",
       "  0.12444908171892166,\n",
       "  0.10933122783899307,\n",
       "  0.09775517135858536,\n",
       "  0.08791666477918625,\n",
       "  0.08090023696422577,\n",
       "  0.07441046088933945,\n",
       "  0.06936510652303696,\n",
       "  0.06499642878770828,\n",
       "  0.061417341232299805,\n",
       "  0.058039210736751556,\n",
       "  0.05544121563434601,\n",
       "  0.05294078215956688,\n",
       "  0.050504740327596664,\n",
       "  0.04861035570502281,\n",
       "  0.04672522097826004,\n",
       "  0.04459597170352936,\n",
       "  0.04359596222639084,\n",
       "  0.041673943400382996,\n",
       "  0.04027028754353523,\n",
       "  0.038866959512233734,\n",
       "  0.037502631545066833,\n",
       "  0.036180946975946426,\n",
       "  0.03499380126595497,\n",
       "  0.034279800951480865,\n",
       "  0.032799214124679565,\n",
       "  0.0321248322725296,\n",
       "  0.030741015449166298,\n",
       "  0.030170250684022903,\n",
       "  0.0287989042699337,\n",
       "  0.027819020673632622,\n",
       "  0.027045750990509987,\n",
       "  0.02595522813498974,\n",
       "  0.025133652612566948,\n",
       "  0.024375416338443756,\n",
       "  0.023538319393992424,\n",
       "  0.022984765470027924,\n",
       "  0.021952293813228607,\n",
       "  0.021374206990003586,\n",
       "  0.020962219685316086,\n",
       "  0.02011803723871708,\n",
       "  0.019484978169202805,\n",
       "  0.018359649926424026,\n",
       "  0.01778164878487587,\n",
       "  0.017194293439388275,\n",
       "  0.016532404348254204,\n",
       "  0.01601417176425457,\n",
       "  0.01561135146766901,\n",
       "  0.015055647119879723,\n",
       "  0.014499404467642307,\n",
       "  0.014083778485655785,\n",
       "  0.013518577441573143,\n",
       "  0.013049270957708359,\n",
       "  0.012808617204427719,\n",
       "  0.012194090522825718,\n",
       "  0.011872014962136745,\n",
       "  0.011490290984511375,\n",
       "  0.01114614773541689,\n",
       "  0.010614880360662937,\n",
       "  0.01040296908468008,\n",
       "  0.009931475855410099,\n",
       "  0.009786377660930157,\n",
       "  0.009260017424821854,\n",
       "  0.008923603221774101,\n",
       "  0.008640618063509464,\n",
       "  0.008348239585757256,\n",
       "  0.00806981697678566,\n",
       "  0.007776207756251097,\n",
       "  0.007576923817396164,\n",
       "  0.0073752994649112225,\n",
       "  0.007009230554103851,\n",
       "  0.00680735195055604,\n",
       "  0.0065759699791669846,\n",
       "  0.006324353627860546,\n",
       "  0.006147544365376234,\n",
       "  0.0059194015339016914,\n",
       "  0.005815231706947088,\n",
       "  0.005594297312200069,\n",
       "  0.00543102715164423,\n",
       "  0.005236229859292507,\n",
       "  0.005107505712658167,\n",
       "  0.0049401866272091866,\n",
       "  0.00486411526799202,\n",
       "  0.004694356117397547,\n",
       "  0.004607683978974819,\n",
       "  0.004468797240406275,\n",
       "  0.004279776941984892,\n",
       "  0.004237745422869921,\n",
       "  0.004078356549143791,\n",
       "  0.003999595530331135,\n",
       "  0.003875372000038624,\n",
       "  0.003764792811125517,\n",
       "  0.0036796927452087402,\n",
       "  0.00359209137968719,\n",
       "  0.0035077461507171392,\n",
       "  0.0033960992004722357,\n",
       "  0.003329387167468667,\n",
       "  0.0032439834903925657,\n",
       "  0.003145323134958744,\n",
       "  0.0030691679567098618,\n",
       "  0.0029887198470532894,\n",
       "  0.002909886883571744,\n",
       "  0.002856283215805888,\n",
       "  0.002775447675958276,\n",
       "  0.0027519341092556715,\n",
       "  0.002668892964720726,\n",
       "  0.002586363349109888,\n",
       "  0.0025810874067246914,\n",
       "  0.0024569735396653414,\n",
       "  0.0024320343509316444,\n",
       "  0.0023798265028744936,\n",
       "  0.0023058478254824877,\n",
       "  0.0022642251569777727,\n",
       "  0.002194683998823166,\n",
       "  0.002147878985852003,\n",
       "  0.002105430932715535,\n",
       "  0.0020684388000518084,\n",
       "  0.0020423366222530603,\n",
       "  0.0019731654319912195,\n",
       "  0.001932622049935162,\n",
       "  0.0018888560589402914,\n",
       "  0.0018562607001513243,\n",
       "  0.0018193770665675402,\n",
       "  0.0017651849193498492,\n",
       "  0.0017373566515743732,\n",
       "  0.0017118178075179458,\n",
       "  0.0016714264638721943,\n",
       "  0.0016279146075248718,\n",
       "  0.0015955395065248013,\n",
       "  0.0015599940670654178,\n",
       "  0.001525377039797604,\n",
       "  0.0014934941427782178,\n",
       "  0.0014665900962427258,\n",
       "  0.0014588622143492103,\n",
       "  0.0014057521475479007,\n",
       "  0.001404601731337607,\n",
       "  0.0013565625995397568,\n",
       "  0.0013271342031657696,\n",
       "  0.0012960179010406137,\n",
       "  0.001266021397896111,\n",
       "  0.0012393166543915868,\n",
       "  0.0012200557393953204,\n",
       "  0.001180566381663084,\n",
       "  0.0011691789841279387,\n",
       "  0.0011689787497743964,\n",
       "  0.0011147407349199057,\n",
       "  0.0011050425237044692,\n",
       "  0.0010686180321499705,\n",
       "  0.0010438294848427176,\n",
       "  0.0010336556006222963,\n",
       "  0.0010119469370692968,\n",
       "  0.000995699199847877,\n",
       "  0.0009747263393364847,\n",
       "  0.0009503122419118881,\n",
       "  0.0009337649680674076,\n",
       "  0.0009138594614341855,\n",
       "  0.0008997840923257172,\n",
       "  0.0008764486410655081,\n",
       "  0.0008759278571233153,\n",
       "  0.0008584955940023065,\n",
       "  0.0008310263510793447,\n",
       "  0.0008146780892275274,\n",
       "  0.0008011180907487869,\n",
       "  0.0007857769378460944,\n",
       "  0.0007667238241992891,\n",
       "  0.0007644625147804618,\n",
       "  0.0007481965003535151,\n",
       "  0.0007397135486826301,\n",
       "  0.0007183732814155519,\n",
       "  0.0006990244728513062,\n",
       "  0.0006960376049391925,\n",
       "  0.0006752923363819718,\n",
       "  0.0006650552968494594,\n",
       "  0.0006516100838780403,\n",
       "  0.0006443081656470895,\n",
       "  0.0006319035310298204,\n",
       "  0.0006197344628162682,\n",
       "  0.0006151240668259561,\n",
       "  0.0005927245947532356,\n",
       "  0.0005909767933189869,\n",
       "  0.0005801465595141053,\n",
       "  0.0005675461143255234,\n",
       "  0.0005632304819300771,\n",
       "  0.0005563109298236668,\n",
       "  0.00054669234668836,\n",
       "  0.0005398455541580915,\n",
       "  0.0005278837052173913,\n",
       "  0.0005153719685040414,\n",
       "  0.0005071469349786639,\n",
       "  0.0004987615393474698,\n",
       "  0.00048609994701109827,\n",
       "  0.0004803167248610407,\n",
       "  0.00046652715536765754,\n",
       "  0.0004655202501453459,\n",
       "  0.0004563838301692158,\n",
       "  0.0004476040485315025,\n",
       "  0.0004538841894827783,\n",
       "  0.0004361329192761332,\n",
       "  0.0004347541544120759,\n",
       "  0.000421404663939029,\n",
       "  0.00041619810508564115,\n",
       "  0.00040577774052508175,\n",
       "  0.0004009659751318395,\n",
       "  0.0003937192668672651,\n",
       "  0.0003878606075886637,\n",
       "  0.0003814644878730178,\n",
       "  0.00037853888352401555,\n",
       "  0.0003711441531777382,\n",
       "  0.00036697127507068217,\n",
       "  0.00035908332210965455,\n",
       "  0.00035678924177773297,\n",
       "  0.0003501272585708648,\n",
       "  0.0003462012973614037,\n",
       "  0.0003400923451408744,\n",
       "  0.0003367061144672334,\n",
       "  0.00033198221353814006,\n",
       "  0.00033221972989849746,\n",
       "  0.00032346241641789675,\n",
       "  0.00031708646565675735,\n",
       "  0.0003103347262367606,\n",
       "  0.00030688109109178185,\n",
       "  0.00030243684886954725,\n",
       "  0.00029782039928250015,\n",
       "  0.0002937051758635789,\n",
       "  0.0002881256805267185,\n",
       "  0.00028649598243646324,\n",
       "  0.0002820558729581535,\n",
       "  0.0002775565080810338,\n",
       "  0.00027641127235256135,\n",
       "  0.0002701568591874093,\n",
       "  0.0002674372517503798,\n",
       "  0.0002636353310663253,\n",
       "  0.00026099770911969244,\n",
       "  0.00025935290614143014,\n",
       "  0.0002530552737880498,\n",
       "  0.00025020091561600566,\n",
       "  0.0002456204383634031,\n",
       "  0.00024506085901521146,\n",
       "  0.00024167251831386238,\n",
       "  0.00023809599224478006,\n",
       "  0.00023401828366331756,\n",
       "  0.0002309207629878074,\n",
       "  0.0002282793866470456,\n",
       "  0.00022703185095451772,\n",
       "  0.0002245348150609061,\n",
       "  0.00022024445934221148,\n",
       "  0.00021616628509946167,\n",
       "  0.00021678375196643174,\n",
       "  0.00021284192916937172,\n",
       "  0.0002076510718325153,\n",
       "  0.00020844388927798718,\n",
       "  0.00020358478650450706,\n",
       "  0.0002002582186833024,\n",
       "  0.00019805821648333222,\n",
       "  0.00019676478405017406,\n",
       "  0.00019390911620575935,\n",
       "  0.00019145901023875922,\n",
       "  0.00018931273370981216,\n",
       "  0.00018706351693253964,\n",
       "  0.00018418594845570624,\n",
       "  0.00018202113278675824,\n",
       "  0.00017969051259569824,\n",
       "  0.00017735747678671032,\n",
       "  0.00017543470312375575,\n",
       "  0.00017318005848210305,\n",
       "  0.00017242493049707264,\n",
       "  0.00016889847756829113,\n",
       "  0.0001678324188105762,\n",
       "  0.00016500605852343142,\n",
       "  0.0001624294527573511,\n",
       "  0.0001620196708245203,\n",
       "  0.00015881983563303947,\n",
       "  0.00015677647024858743,\n",
       "  0.0001548055442981422,\n",
       "  0.00015689116844441742,\n",
       "  0.00015098589938133955,\n",
       "  0.00015082696336321533,\n",
       "  0.00014801818178966641,\n",
       "  0.00014578633999917656,\n",
       "  0.00014591569197364151,\n",
       "  0.00014375294267665595,\n",
       "  0.000140713804285042,\n",
       "  0.00013984862016513944,\n",
       "  0.0001381761976517737,\n",
       "  0.00013500980276148766,\n",
       "  0.00013515102909877896,\n",
       "  0.0001334317057626322,\n",
       "  0.00013179128291085362,\n",
       "  0.00013000410399399698,\n",
       "  0.00012878177221864462,\n",
       "  0.00012703705579042435,\n",
       "  0.00012544203491415828,\n",
       "  0.0001247678737854585,\n",
       "  0.00012303049152251333,\n",
       "  0.00012135135330026969,\n",
       "  0.0001195482473121956,\n",
       "  0.00011884486593771726,\n",
       "  0.00011716246081050485,\n",
       "  0.00011677269503707066,\n",
       "  0.00011533671204233542,\n",
       "  0.00011391250882297754,\n",
       "  0.00011229315714444965,\n",
       "  0.00011159292625961825,\n",
       "  0.00011096103844465688,\n",
       "  0.00010986639972543344,\n",
       "  0.00010721766739152372,\n",
       "  0.00010651427874108776,\n",
       "  0.00010568113066256046,\n",
       "  0.00010447831300552934,\n",
       "  0.00010249100887449458,\n",
       "  0.00010157754877582192,\n",
       "  0.00010223100980510935,\n",
       "  0.00010049608681583777,\n",
       "  9.890586807159707e-05,\n",
       "  9.741066605783999e-05,\n",
       "  9.629682608647272e-05,\n",
       "  9.562123887008056e-05,\n",
       "  9.418842091690749e-05,\n",
       "  9.321532706962898e-05,\n",
       "  9.343584679299966e-05,\n",
       "  9.123938070842996e-05,\n",
       "  9.017548291012645e-05,\n",
       "  8.989874186227098e-05,\n",
       "  8.851466554915532e-05,\n",
       "  8.796502515906468e-05,\n",
       "  8.703559433342889e-05,\n",
       "  8.670044917380437e-05,\n",
       "  8.532510400982574e-05,\n",
       "  8.44599780975841e-05,\n",
       "  8.331937715411186e-05,\n",
       "  8.280894689960405e-05,\n",
       "  8.123148290906101e-05,\n",
       "  8.074848301475868e-05,\n",
       "  7.948362326715142e-05,\n",
       "  7.919807831058279e-05,\n",
       "  7.816225115675479e-05,\n",
       "  7.805634231772274e-05,\n",
       "  7.665952580282465e-05,\n",
       "  7.599901437060907e-05,\n",
       "  7.517237827414647e-05,\n",
       "  7.484144589398056e-05,\n",
       "  7.330318476306275e-05,\n",
       "  7.289511268027127e-05,\n",
       "  7.236000965349376e-05,\n",
       "  7.182443368947133e-05,\n",
       "  7.102715608198196e-05,\n",
       "  7.022192585282028e-05,\n",
       "  6.980889156693593e-05,\n",
       "  6.84873666614294e-05,\n",
       "  6.796188245061785e-05,\n",
       "  6.748153828084469e-05,\n",
       "  6.731319444952533e-05,\n",
       "  6.597931496798992e-05,\n",
       "  6.552896957146004e-05,\n",
       "  6.531058170367032e-05,\n",
       "  6.435274553950876e-05,\n",
       "  6.374200893333182e-05,\n",
       "  6.294749618973583e-05,\n",
       "  6.207871774677187e-05,\n",
       "  6.193759327288717e-05,\n",
       "  6.104406929807737e-05,\n",
       "  6.059928273316473e-05,\n",
       "  6.029902215232141e-05,\n",
       "  5.942244388279505e-05,\n",
       "  5.8798326790565625e-05,\n",
       "  5.8621997595764697e-05,\n",
       "  5.8484638429945335e-05,\n",
       "  5.7362529332749546e-05,\n",
       "  5.6702967413002625e-05,\n",
       "  5.6034659792203456e-05,\n",
       "  5.53854915779084e-05,\n",
       "  5.512626012205146e-05,\n",
       "  5.4699663451174274e-05,\n",
       "  5.390070145949721e-05,\n",
       "  5.354162567527965e-05,\n",
       "  5.305631930241361e-05,\n",
       "  5.242140468908474e-05,\n",
       "  5.246214641374536e-05,\n",
       "  5.163778769201599e-05,\n",
       "  5.135474930284545e-05,\n",
       "  5.059324757894501e-05,\n",
       "  5.028180021326989e-05,\n",
       "  4.942905070492998e-05,\n",
       "  4.884770532953553e-05,\n",
       "  4.87378601974342e-05,\n",
       "  4.828164674108848e-05,\n",
       "  4.818443994736299e-05,\n",
       "  4.772150350618176e-05,\n",
       "  4.6673281758558005e-05,\n",
       "  4.6446166379610077e-05,\n",
       "  4.58041213278193e-05,\n",
       "  4.550469384412281e-05,\n",
       "  4.5266293454915285e-05,\n",
       "  4.506266850512475e-05,\n",
       "  4.422552228788845e-05,\n",
       "  4.3746749724959955e-05,\n",
       "  4.351301322458312e-05,\n",
       "  4.307495692046359e-05,\n",
       "  4.2559157009236515e-05,\n",
       "  4.2308874981245026e-05,\n",
       "  4.172313492745161e-05,\n",
       "  4.1296672861790285e-05,\n",
       "  4.1171446355292574e-05,\n",
       "  4.067198824486695e-05,\n",
       "  4.0352068026550114e-05,\n",
       "  3.973624552600086e-05,\n",
       "  3.951802136725746e-05,\n",
       "  3.9058235415723175e-05,\n",
       "  3.91019566450268e-05,\n",
       "  3.846632898785174e-05,\n",
       "  3.8274381950031966e-05,\n",
       "  3.79472658096347e-05,\n",
       "  3.730102616827935e-05,\n",
       "  3.698093496495858e-05,\n",
       "  3.652718078228645e-05,\n",
       "  3.623019438236952e-05,\n",
       "  3.5762124753091484e-05,\n",
       "  3.5896118788514286e-05,\n",
       "  3.539720637490973e-05,\n",
       "  3.529102832544595e-05,\n",
       "  3.488656511763111e-05,\n",
       "  3.446557093411684e-05,\n",
       "  3.408772317925468e-05,\n",
       "  3.383572766324505e-05,\n",
       "  3.3371175959473476e-05,\n",
       "  3.3349497243762016e-05,\n",
       "  3.267163265263662e-05,\n",
       "  3.230172660551034e-05,\n",
       "  3.1931089324643835e-05,\n",
       "  3.176607424393296e-05,\n",
       "  3.1499228498432785e-05,\n",
       "  3.1232724722940475e-05,\n",
       "  3.125000148429535e-05,\n",
       "  3.0607898224843666e-05,\n",
       "  3.052503234357573e-05,\n",
       "  3.004204700118862e-05,\n",
       "  2.991700057464186e-05,\n",
       "  2.954011142719537e-05,\n",
       "  2.9245809855638072e-05,\n",
       "  2.907557791331783e-05,\n",
       "  2.87995226244675e-05,\n",
       "  2.870177740987856e-05,\n",
       "  2.8205740818521008e-05,\n",
       "  2.816153755702544e-05,\n",
       "  2.7872925784322433e-05,\n",
       "  2.7618278181762435e-05,\n",
       "  2.7488857085700147e-05,\n",
       "  2.706798659346532e-05,\n",
       "  2.6905356207862496e-05,\n",
       "  2.686194966372568e-05,\n",
       "  2.632640826050192e-05,\n",
       "  2.6119405447389e-05,\n",
       "  2.58937416219851e-05,\n",
       "  2.558946653152816e-05,\n",
       "  2.5456529328948818e-05,\n",
       "  2.51440578722395e-05,\n",
       "  2.5156450647045858e-05,\n",
       "  2.4715145627851598e-05,\n",
       "  2.48240030487068e-05,\n",
       "  2.4546394342905842e-05,\n",
       "  2.4267734261229634e-05,\n",
       "  2.3943191990838386e-05,\n",
       "  2.372380367887672e-05,\n",
       "  2.3551487174700014e-05,\n",
       "  2.3249440346262418e-05,\n",
       "  2.327514266653452e-05,\n",
       "  2.2993221136857755e-05,\n",
       "  2.304566623934079e-05,\n",
       "  2.2623426048085093e-05,\n",
       "  2.233925260952674e-05,\n",
       "  2.2171214368427172e-05,\n",
       "  2.1893822122365236e-05,\n",
       "  2.1675610696547665e-05,\n",
       "  2.1446028767968528e-05,\n",
       "  2.127257721440401e-05,\n",
       "  2.1222356735961512e-05,\n",
       "  2.125110404449515e-05,\n",
       "  2.0886935089947656e-05,\n",
       "  2.063706051558256e-05,\n",
       "  2.0415147446328774e-05,\n",
       "  2.0387093172757886e-05,\n",
       "  2.0057470464962535e-05,\n",
       "  1.9930150301661342e-05,\n",
       "  1.977575993805658e-05,\n",
       "  1.9560238797566853e-05,\n",
       "  1.947255077539012e-05,\n",
       "  1.9250932382419705e-05,\n",
       "  1.907930891320575e-05,\n",
       "  1.893071021186188e-05,\n",
       "  1.8819035176420584e-05,\n",
       "  1.86470897460822e-05,\n",
       "  1.8456124962540343e-05,\n",
       "  1.8350569007452577e-05,\n",
       "  1.815647556213662e-05,\n",
       "  1.8041449948213995e-05,\n",
       "  1.7945463696378283e-05,\n",
       "  1.7755268345354125e-05,\n",
       "  1.7783288058126345e-05,\n",
       "  1.7448561266064644e-05,\n",
       "  1.723712557577528e-05,\n",
       "  1.7139702322310768e-05,\n",
       "  1.7051655959221534e-05,\n",
       "  1.68461865541758e-05,\n",
       "  1.6684811271261424e-05,\n",
       "  1.6583151591476053e-05,\n",
       "  1.6559741197852418e-05,\n",
       "  1.633358988328837e-05,\n",
       "  1.631091618037317e-05,\n",
       "  1.5939549484755844e-05,\n",
       "  1.6066089301602915e-05,\n",
       "  1.5857172911637463e-05,\n",
       "  1.5644045561202802e-05,\n",
       "  1.552746834931895e-05,\n",
       "  1.5315912605728954e-05,\n",
       "  1.5272846212610602e-05,\n",
       "  1.5113483641471248e-05,\n",
       "  1.4998834558355156e-05,\n",
       "  1.477941532357363e-05,\n",
       "  1.4630534678872209e-05,\n",
       "  1.457935377402464e-05,\n",
       "  1.4480157915386371e-05,\n",
       "  1.4345860108733177e-05,\n",
       "  1.4244898011384066e-05,\n",
       "  1.4157826626615133e-05,\n",
       "  1.4033108527655713e-05,\n",
       "  1.382609480060637e-05,\n",
       "  1.3772439160675276e-05,\n",
       "  1.3630549801746383e-05,\n",
       "  1.3461953130899929e-05,\n",
       "  1.3497056897904258e-05,\n",
       "  1.3250856682134327e-05,\n",
       "  1.3319428944669198e-05,\n",
       "  1.3119549294060562e-05,\n",
       "  1.2961269931111019e-05,\n",
       "  1.2871941180492286e-05,\n",
       "  1.2733792573271785e-05,\n",
       "  1.2620800589502323e-05,\n",
       "  1.2517429240688216e-05,\n",
       "  1.2422903637343552e-05,\n",
       "  1.236385742231505e-05,\n",
       "  1.2220168173371349e-05,\n",
       "  1.2213704394525848e-05,\n",
       "  1.1962692951783538e-05,\n",
       "  1.1886122592841275e-05,\n",
       "  1.1838971659017261e-05,\n",
       "  1.169029110315023e-05,\n",
       "  1.165162666438846e-05,\n",
       "  1.1490556062199175e-05,\n",
       "  1.1471232028270606e-05,\n",
       "  1.146560134657193e-05,\n",
       "  1.1265411558269989e-05,\n",
       "  1.1238559636694845e-05,\n",
       "  1.111517303797882e-05,\n",
       "  1.1097288734163158e-05,\n",
       "  1.0985831067955587e-05,\n",
       "  1.0790037777042016e-05,\n",
       "  1.073081966751488e-05,\n",
       "  1.0572476639936212e-05,\n",
       "  1.0554015716479626e-05,\n",
       "  1.0443578503327444e-05,\n",
       "  1.0389909220975824e-05,\n",
       "  1.0245369594485965e-05,\n",
       "  1.0197221854468808e-05,\n",
       "  1.0161224054172635e-05,\n",
       "  9.990099897549953e-06,\n",
       "  9.958795089914929e-06,\n",
       "  9.81217272055801e-06,\n",
       "  9.738216249388643e-06,\n",
       "  9.670729014032986e-06,\n",
       "  9.562276318320073e-06,\n",
       "  9.526725079922471e-06,\n",
       "  9.412770850758534e-06,\n",
       "  9.363729986944236e-06,\n",
       "  9.289742592955008e-06,\n",
       "  9.22928211366525e-06,\n",
       "  9.11800452740863e-06,\n",
       "  9.090134881262202e-06,\n",
       "  8.984685337054543e-06,\n",
       "  8.953754331741948e-06,\n",
       "  8.88512749952497e-06,\n",
       "  8.776371942076366e-06,\n",
       "  8.737647476664279e-06,\n",
       "  8.7000053099473e-06,\n",
       "  8.590377547079697e-06,\n",
       "  8.542974683223292e-06,\n",
       "  8.404783329751808e-06,\n",
       "  8.408736903220415e-06,\n",
       "  8.336686732945964e-06,\n",
       "  8.234166671172716e-06,\n",
       "  8.2425713117118e-06,\n",
       "  8.10053461464122e-06,\n",
       "  8.034038728510495e-06,\n",
       "  7.974695108714513e-06,\n",
       "  7.916334652691148e-06,\n",
       "  7.87022781878477e-06],\n",
       " 'val_loss': [0.48184439539909363,\n",
       "  0.3502993583679199,\n",
       "  0.2762990891933441,\n",
       "  0.23111988604068756,\n",
       "  0.19726094603538513,\n",
       "  0.1731903851032257,\n",
       "  0.15569919347763062,\n",
       "  0.1419789344072342,\n",
       "  0.13050957024097443,\n",
       "  0.12284226715564728,\n",
       "  0.11612660437822342,\n",
       "  0.11144808679819107,\n",
       "  0.1081220954656601,\n",
       "  0.10510590672492981,\n",
       "  0.10235727578401566,\n",
       "  0.1007731482386589,\n",
       "  0.09941425919532776,\n",
       "  0.09804551303386688,\n",
       "  0.09690100699663162,\n",
       "  0.09552132338285446,\n",
       "  0.09460931271314621,\n",
       "  0.09455826133489609,\n",
       "  0.0948227196931839,\n",
       "  0.09423939883708954,\n",
       "  0.09332139045000076,\n",
       "  0.09262467920780182,\n",
       "  0.09294260293245316,\n",
       "  0.09280669689178467,\n",
       "  0.09239709377288818,\n",
       "  0.09185074269771576,\n",
       "  0.0914483591914177,\n",
       "  0.09172969311475754,\n",
       "  0.09027939289808273,\n",
       "  0.08970532566308975,\n",
       "  0.08947748690843582,\n",
       "  0.09004713594913483,\n",
       "  0.09019361436367035,\n",
       "  0.08993162959814072,\n",
       "  0.08992758393287659,\n",
       "  0.08970260620117188,\n",
       "  0.08980440348386765,\n",
       "  0.08992154151201248,\n",
       "  0.08939721435308456,\n",
       "  0.08909650146961212,\n",
       "  0.08947160840034485,\n",
       "  0.08931509405374527,\n",
       "  0.08943820744752884,\n",
       "  0.08890727162361145,\n",
       "  0.08883997052907944,\n",
       "  0.08924102783203125,\n",
       "  0.08941943943500519,\n",
       "  0.08941088616847992,\n",
       "  0.08961427211761475,\n",
       "  0.08956936746835709,\n",
       "  0.08964136242866516,\n",
       "  0.08965159952640533,\n",
       "  0.08974669128656387,\n",
       "  0.09018723666667938,\n",
       "  0.09016314148902893,\n",
       "  0.09026070684194565,\n",
       "  0.09024792164564133,\n",
       "  0.09086143970489502,\n",
       "  0.09120798110961914,\n",
       "  0.09171956032514572,\n",
       "  0.09185086190700531,\n",
       "  0.09145732969045639,\n",
       "  0.0915662869811058,\n",
       "  0.09151623398065567,\n",
       "  0.09222475439310074,\n",
       "  0.09263637661933899,\n",
       "  0.09331979602575302,\n",
       "  0.09375306963920593,\n",
       "  0.09416784346103668,\n",
       "  0.09486004710197449,\n",
       "  0.09492165595293045,\n",
       "  0.09545864164829254,\n",
       "  0.0954221859574318,\n",
       "  0.09592556208372116,\n",
       "  0.0963735431432724,\n",
       "  0.09668543189764023,\n",
       "  0.09706733375787735,\n",
       "  0.09702180325984955,\n",
       "  0.09758204221725464,\n",
       "  0.09771694988012314,\n",
       "  0.09813039749860764,\n",
       "  0.09833840280771255,\n",
       "  0.09873072057962418,\n",
       "  0.09958820790052414,\n",
       "  0.1001364141702652,\n",
       "  0.10060678422451019,\n",
       "  0.10092528164386749,\n",
       "  0.10152359306812286,\n",
       "  0.10221803933382034,\n",
       "  0.10198452323675156,\n",
       "  0.1024344339966774,\n",
       "  0.10263057053089142,\n",
       "  0.10312697291374207,\n",
       "  0.10337826609611511,\n",
       "  0.10349641740322113,\n",
       "  0.10423006862401962,\n",
       "  0.10453814268112183,\n",
       "  0.10499893873929977,\n",
       "  0.10540684312582016,\n",
       "  0.10555057972669601,\n",
       "  0.105793297290802,\n",
       "  0.10616574436426163,\n",
       "  0.10630225390195847,\n",
       "  0.10674001276493073,\n",
       "  0.10744442790746689,\n",
       "  0.10782784223556519,\n",
       "  0.10855802148580551,\n",
       "  0.10873489081859589,\n",
       "  0.10895200073719025,\n",
       "  0.10973858833312988,\n",
       "  0.10998326539993286,\n",
       "  0.11057005077600479,\n",
       "  0.11064841598272324,\n",
       "  0.1116548404097557,\n",
       "  0.1119437962770462,\n",
       "  0.11215057224035263,\n",
       "  0.11240646988153458,\n",
       "  0.11276907473802567,\n",
       "  0.11316440254449844,\n",
       "  0.11327958852052689,\n",
       "  0.11369303613901138,\n",
       "  0.11392776668071747,\n",
       "  0.11424939334392548,\n",
       "  0.11452379077672958,\n",
       "  0.11502701044082642,\n",
       "  0.11542563140392303,\n",
       "  0.11575257033109665,\n",
       "  0.11595813930034637,\n",
       "  0.11593278497457504,\n",
       "  0.11654742062091827,\n",
       "  0.11729303002357483,\n",
       "  0.11753549426794052,\n",
       "  0.11772459000349045,\n",
       "  0.11859966069459915,\n",
       "  0.11937038600444794,\n",
       "  0.1193898394703865,\n",
       "  0.11930427700281143,\n",
       "  0.120583675801754,\n",
       "  0.12101197987794876,\n",
       "  0.12127531319856644,\n",
       "  0.12145556509494781,\n",
       "  0.12178988009691238,\n",
       "  0.1225145161151886,\n",
       "  0.12279211729764938,\n",
       "  0.12334336340427399,\n",
       "  0.12346736341714859,\n",
       "  0.12390545010566711,\n",
       "  0.12489102780818939,\n",
       "  0.125272735953331,\n",
       "  0.1255030483007431,\n",
       "  0.12606433033943176,\n",
       "  0.1263909935951233,\n",
       "  0.12683194875717163,\n",
       "  0.12722796201705933,\n",
       "  0.12767767906188965,\n",
       "  0.1279124617576599,\n",
       "  0.12813371419906616,\n",
       "  0.12865255773067474,\n",
       "  0.12879085540771484,\n",
       "  0.1287192404270172,\n",
       "  0.12978675961494446,\n",
       "  0.13008058071136475,\n",
       "  0.13037149608135223,\n",
       "  0.13068106770515442,\n",
       "  0.1307799518108368,\n",
       "  0.13138963282108307,\n",
       "  0.13172240555286407,\n",
       "  0.13203397393226624,\n",
       "  0.13248707354068756,\n",
       "  0.13290801644325256,\n",
       "  0.13324755430221558,\n",
       "  0.13364581763744354,\n",
       "  0.13393524289131165,\n",
       "  0.13423636555671692,\n",
       "  0.13487103581428528,\n",
       "  0.13512293994426727,\n",
       "  0.13503681123256683,\n",
       "  0.13558313250541687,\n",
       "  0.13610906898975372,\n",
       "  0.13604658842086792,\n",
       "  0.13624908030033112,\n",
       "  0.1365441530942917,\n",
       "  0.1369931399822235,\n",
       "  0.13826914131641388,\n",
       "  0.13846156001091003,\n",
       "  0.1384533941745758,\n",
       "  0.13861972093582153,\n",
       "  0.13889478147029877,\n",
       "  0.13930192589759827,\n",
       "  0.13975566625595093,\n",
       "  0.1397787630558014,\n",
       "  0.14038637280464172,\n",
       "  0.14062350988388062,\n",
       "  0.14161835610866547,\n",
       "  0.1420612782239914,\n",
       "  0.14215520024299622,\n",
       "  0.14235301315784454,\n",
       "  0.14260506629943848,\n",
       "  0.14293290674686432,\n",
       "  0.14351576566696167,\n",
       "  0.14391382038593292,\n",
       "  0.1441165804862976,\n",
       "  0.1444590538740158,\n",
       "  0.1446717232465744,\n",
       "  0.14514929056167603,\n",
       "  0.1456419825553894,\n",
       "  0.14598731696605682,\n",
       "  0.14624665677547455,\n",
       "  0.146572083234787,\n",
       "  0.14685317873954773,\n",
       "  0.1471228301525116,\n",
       "  0.14728286862373352,\n",
       "  0.14781077206134796,\n",
       "  0.14795957505702972,\n",
       "  0.14832311868667603,\n",
       "  0.14855661988258362,\n",
       "  0.14887163043022156,\n",
       "  0.14963340759277344,\n",
       "  0.14974626898765564,\n",
       "  0.15014758706092834,\n",
       "  0.15026497840881348,\n",
       "  0.15073667466640472,\n",
       "  0.15081915259361267,\n",
       "  0.15121044218540192,\n",
       "  0.15149030089378357,\n",
       "  0.1516486257314682,\n",
       "  0.15190954506397247,\n",
       "  0.1522170454263687,\n",
       "  0.15268449485301971,\n",
       "  0.1531272977590561,\n",
       "  0.15355578064918518,\n",
       "  0.15373890101909637,\n",
       "  0.15391086041927338,\n",
       "  0.15432879328727722,\n",
       "  0.15452493727207184,\n",
       "  0.15557321906089783,\n",
       "  0.1557992696762085,\n",
       "  0.15592101216316223,\n",
       "  0.15612564980983734,\n",
       "  0.15693263709545135,\n",
       "  0.15688635408878326,\n",
       "  0.15720990300178528,\n",
       "  0.1574941724538803,\n",
       "  0.15757715702056885,\n",
       "  0.1587526500225067,\n",
       "  0.158640056848526,\n",
       "  0.15886983275413513,\n",
       "  0.15909898281097412,\n",
       "  0.15989571809768677,\n",
       "  0.16005556285381317,\n",
       "  0.1602405160665512,\n",
       "  0.1604064404964447,\n",
       "  0.16079658269882202,\n",
       "  0.16096997261047363,\n",
       "  0.16124865412712097,\n",
       "  0.16152088344097137,\n",
       "  0.1617877036333084,\n",
       "  0.1620354801416397,\n",
       "  0.1622997671365738,\n",
       "  0.16266261041164398,\n",
       "  0.16295427083969116,\n",
       "  0.16313080489635468,\n",
       "  0.16347745060920715,\n",
       "  0.16381578147411346,\n",
       "  0.1641538292169571,\n",
       "  0.16436704993247986,\n",
       "  0.16477151215076447,\n",
       "  0.16487744450569153,\n",
       "  0.16502122581005096,\n",
       "  0.165455162525177,\n",
       "  0.16581833362579346,\n",
       "  0.16598036885261536,\n",
       "  0.16639529168605804,\n",
       "  0.16642752289772034,\n",
       "  0.16669146716594696,\n",
       "  0.16714198887348175,\n",
       "  0.16755013167858124,\n",
       "  0.1679093837738037,\n",
       "  0.168083056807518,\n",
       "  0.16823206841945648,\n",
       "  0.16840329766273499,\n",
       "  0.1688317358493805,\n",
       "  0.16888341307640076,\n",
       "  0.16946296393871307,\n",
       "  0.17004020512104034,\n",
       "  0.17015857994556427,\n",
       "  0.1701444387435913,\n",
       "  0.17070011794567108,\n",
       "  0.1710980236530304,\n",
       "  0.17123113572597504,\n",
       "  0.17130625247955322,\n",
       "  0.17162209749221802,\n",
       "  0.17190109193325043,\n",
       "  0.17205271124839783,\n",
       "  0.17246361076831818,\n",
       "  0.17276699841022491,\n",
       "  0.1728423535823822,\n",
       "  0.17339865863323212,\n",
       "  0.17370851337909698,\n",
       "  0.17383264005184174,\n",
       "  0.17424875497817993,\n",
       "  0.17463535070419312,\n",
       "  0.1744418889284134,\n",
       "  0.17460870742797852,\n",
       "  0.17511217296123505,\n",
       "  0.1751122623682022,\n",
       "  0.1758624166250229,\n",
       "  0.17617690563201904,\n",
       "  0.17636387050151825,\n",
       "  0.1763564795255661,\n",
       "  0.1768403798341751,\n",
       "  0.17726315557956696,\n",
       "  0.17733816802501678,\n",
       "  0.17760784924030304,\n",
       "  0.17788660526275635,\n",
       "  0.1781175434589386,\n",
       "  0.1783863604068756,\n",
       "  0.17841404676437378,\n",
       "  0.1789536327123642,\n",
       "  0.1791093796491623,\n",
       "  0.17918623983860016,\n",
       "  0.1797414869070053,\n",
       "  0.18003326654434204,\n",
       "  0.18031872808933258,\n",
       "  0.1805342137813568,\n",
       "  0.18080216646194458,\n",
       "  0.18095630407333374,\n",
       "  0.18192632496356964,\n",
       "  0.18201065063476562,\n",
       "  0.18233546614646912,\n",
       "  0.1827620416879654,\n",
       "  0.18255707621574402,\n",
       "  0.18292340636253357,\n",
       "  0.18308526277542114,\n",
       "  0.18347559869289398,\n",
       "  0.18363098800182343,\n",
       "  0.18383385241031647,\n",
       "  0.18410134315490723,\n",
       "  0.18409529328346252,\n",
       "  0.18421928584575653,\n",
       "  0.18467405438423157,\n",
       "  0.18484315276145935,\n",
       "  0.18507151305675507,\n",
       "  0.18530955910682678,\n",
       "  0.18559741973876953,\n",
       "  0.185939759016037,\n",
       "  0.18592990934848785,\n",
       "  0.18634352087974548,\n",
       "  0.1866152137517929,\n",
       "  0.1867447793483734,\n",
       "  0.186983123421669,\n",
       "  0.18714433908462524,\n",
       "  0.18757040798664093,\n",
       "  0.18767794966697693,\n",
       "  0.18781065940856934,\n",
       "  0.18818816542625427,\n",
       "  0.18853969871997833,\n",
       "  0.18863584101200104,\n",
       "  0.1888771504163742,\n",
       "  0.18910720944404602,\n",
       "  0.18946555256843567,\n",
       "  0.18966969847679138,\n",
       "  0.1898866891860962,\n",
       "  0.19024841487407684,\n",
       "  0.19063478708267212,\n",
       "  0.19094444811344147,\n",
       "  0.19085775315761566,\n",
       "  0.19175702333450317,\n",
       "  0.1920904666185379,\n",
       "  0.19203320145606995,\n",
       "  0.19226662814617157,\n",
       "  0.19245877861976624,\n",
       "  0.1926150619983673,\n",
       "  0.19303427636623383,\n",
       "  0.1930990368127823,\n",
       "  0.19310414791107178,\n",
       "  0.19341018795967102,\n",
       "  0.1935909390449524,\n",
       "  0.1938922107219696,\n",
       "  0.19400903582572937,\n",
       "  0.19470667839050293,\n",
       "  0.19482344388961792,\n",
       "  0.1951407492160797,\n",
       "  0.19524244964122772,\n",
       "  0.19559520483016968,\n",
       "  0.19598931074142456,\n",
       "  0.19600224494934082,\n",
       "  0.19641940295696259,\n",
       "  0.1966795176267624,\n",
       "  0.19697046279907227,\n",
       "  0.1970810443162918,\n",
       "  0.1975119709968567,\n",
       "  0.19766320288181305,\n",
       "  0.19792474806308746,\n",
       "  0.19798459112644196,\n",
       "  0.19834741950035095,\n",
       "  0.19870920479297638,\n",
       "  0.19877490401268005,\n",
       "  0.19944912195205688,\n",
       "  0.19948044419288635,\n",
       "  0.1995774209499359,\n",
       "  0.19984078407287598,\n",
       "  0.2002401500940323,\n",
       "  0.20042303204536438,\n",
       "  0.2009621262550354,\n",
       "  0.20092996954917908,\n",
       "  0.20128712058067322,\n",
       "  0.20145739614963531,\n",
       "  0.20180025696754456,\n",
       "  0.2017716020345688,\n",
       "  0.20182372629642487,\n",
       "  0.202193945646286,\n",
       "  0.20247045159339905,\n",
       "  0.20285236835479736,\n",
       "  0.20350170135498047,\n",
       "  0.2035573273897171,\n",
       "  0.20377947390079498,\n",
       "  0.20412354171276093,\n",
       "  0.204241082072258,\n",
       "  0.20432141423225403,\n",
       "  0.20457741618156433,\n",
       "  0.20474116504192352,\n",
       "  0.20528313517570496,\n",
       "  0.2053530067205429,\n",
       "  0.2053195685148239,\n",
       "  0.20597516000270844,\n",
       "  0.20635533332824707,\n",
       "  0.20643670856952667,\n",
       "  0.20679591596126556,\n",
       "  0.20673976838588715,\n",
       "  0.20704548060894012,\n",
       "  0.20740625262260437,\n",
       "  0.20739105343818665,\n",
       "  0.20743484795093536,\n",
       "  0.2079072892665863,\n",
       "  0.20825845003128052,\n",
       "  0.2083810567855835,\n",
       "  0.20848751068115234,\n",
       "  0.20881260931491852,\n",
       "  0.2090674489736557,\n",
       "  0.2091706097126007,\n",
       "  0.2093329131603241,\n",
       "  0.2096637636423111,\n",
       "  0.20980776846408844,\n",
       "  0.2099720984697342,\n",
       "  0.21023854613304138,\n",
       "  0.2109919786453247,\n",
       "  0.21113424003124237,\n",
       "  0.2113412618637085,\n",
       "  0.2113252431154251,\n",
       "  0.21192827820777893,\n",
       "  0.21194614470005035,\n",
       "  0.2121157944202423,\n",
       "  0.2124217450618744,\n",
       "  0.21258507668972015,\n",
       "  0.2129468023777008,\n",
       "  0.21311506628990173,\n",
       "  0.2134711742401123,\n",
       "  0.21364836394786835,\n",
       "  0.21373532712459564,\n",
       "  0.21395516395568848,\n",
       "  0.2141464799642563,\n",
       "  0.21444173157215118,\n",
       "  0.21476903557777405,\n",
       "  0.21483975648880005,\n",
       "  0.21502433717250824,\n",
       "  0.2152600884437561,\n",
       "  0.21510198712348938,\n",
       "  0.21545390784740448,\n",
       "  0.21558208763599396,\n",
       "  0.21608760952949524,\n",
       "  0.21622394025325775,\n",
       "  0.21668311953544617,\n",
       "  0.21697880327701569,\n",
       "  0.21710608899593353,\n",
       "  0.21733707189559937,\n",
       "  0.2173098921775818,\n",
       "  0.21822752058506012,\n",
       "  0.21837890148162842,\n",
       "  0.21840587258338928,\n",
       "  0.21845132112503052,\n",
       "  0.21891336143016815,\n",
       "  0.21900299191474915,\n",
       "  0.21927116811275482,\n",
       "  0.21935711801052094,\n",
       "  0.21977776288986206,\n",
       "  0.22006715834140778,\n",
       "  0.22028090059757233,\n",
       "  0.22049541771411896,\n",
       "  0.22071170806884766,\n",
       "  0.22091500461101532,\n",
       "  0.22091326117515564,\n",
       "  0.22105556726455688,\n",
       "  0.22154083847999573,\n",
       "  0.221700519323349,\n",
       "  0.2218630164861679,\n",
       "  0.22205379605293274,\n",
       "  0.22245514392852783,\n",
       "  0.22280021011829376,\n",
       "  0.22289109230041504,\n",
       "  0.22300074994564056,\n",
       "  0.22325736284255981,\n",
       "  0.22343091666698456,\n",
       "  0.22367390990257263,\n",
       "  0.22379757463932037,\n",
       "  0.2241542488336563,\n",
       "  0.22446633875370026,\n",
       "  0.22452639043331146,\n",
       "  0.22458593547344208,\n",
       "  0.224901482462883,\n",
       "  0.22510379552841187,\n",
       "  0.22525256872177124,\n",
       "  0.22562898695468903,\n",
       "  0.2257353514432907,\n",
       "  0.22604838013648987,\n",
       "  0.22641053795814514,\n",
       "  0.22654472291469574,\n",
       "  0.2268487513065338,\n",
       "  0.22717541456222534,\n",
       "  0.22744415700435638,\n",
       "  0.22757793962955475,\n",
       "  0.2278623729944229,\n",
       "  0.22808344662189484,\n",
       "  0.2280612289905548,\n",
       "  0.22889356315135956,\n",
       "  0.2289356142282486,\n",
       "  0.22939515113830566,\n",
       "  0.22972486913204193,\n",
       "  0.22982953488826752,\n",
       "  0.22991377115249634,\n",
       "  0.23017147183418274,\n",
       "  0.2303704172372818,\n",
       "  0.23038806021213531,\n",
       "  0.23083728551864624,\n",
       "  0.2311079055070877,\n",
       "  0.23136457800865173,\n",
       "  0.23126816749572754,\n",
       "  0.23162105679512024,\n",
       "  0.23195773363113403,\n",
       "  0.23219093680381775,\n",
       "  0.2320774793624878,\n",
       "  0.2323439121246338,\n",
       "  0.23283055424690247,\n",
       "  0.23294353485107422,\n",
       "  0.23320244252681732,\n",
       "  0.23309412598609924,\n",
       "  0.23357485234737396,\n",
       "  0.233607217669487,\n",
       "  0.23398159444332123,\n",
       "  0.23423542082309723,\n",
       "  0.2345520555973053,\n",
       "  0.23464785516262054,\n",
       "  0.23489563167095184,\n",
       "  0.23510459065437317,\n",
       "  0.2351696789264679,\n",
       "  0.23546075820922852,\n",
       "  0.23591797053813934,\n",
       "  0.2361014485359192,\n",
       "  0.23632171750068665,\n",
       "  0.23655515909194946,\n",
       "  0.23666122555732727,\n",
       "  0.23707236349582672,\n",
       "  0.2371603101491928,\n",
       "  0.2372855544090271,\n",
       "  0.23780930042266846,\n",
       "  0.2379837930202484,\n",
       "  0.238177090883255,\n",
       "  0.238472118973732,\n",
       "  0.23852351307868958,\n",
       "  0.2389434278011322,\n",
       "  0.23908178508281708,\n",
       "  0.23905761539936066,\n",
       "  0.2393638640642166,\n",
       "  0.23958295583724976,\n",
       "  0.23971852660179138,\n",
       "  0.2400962859392166,\n",
       "  0.24024738371372223,\n",
       "  0.24051612615585327,\n",
       "  0.24060353636741638,\n",
       "  0.241058811545372,\n",
       "  0.24115729331970215,\n",
       "  0.24135339260101318,\n",
       "  0.24171856045722961,\n",
       "  0.24175970256328583,\n",
       "  0.2420431226491928,\n",
       "  0.24214933812618256,\n",
       "  0.24253763258457184,\n",
       "  0.24295911192893982,\n",
       "  0.24295452237129211,\n",
       "  0.2432008981704712,\n",
       "  0.24313214421272278,\n",
       "  0.2436094880104065,\n",
       "  0.24401091039180756,\n",
       "  0.24403995275497437,\n",
       "  0.24442337453365326,\n",
       "  0.24463137984275818]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "executionInfo": {
     "elapsed": 500,
     "status": "ok",
     "timestamp": 1657211106609,
     "user": {
      "displayName": "Darshan Darshu",
      "userId": "08066444614316366436"
     },
     "user_tz": -330
    },
    "id": "5_rb-yS-qxX-",
    "outputId": "da3fd0a5-12fa-4968-9f3c-28fc2077ab8a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f267f576a90>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lossdf=pd.DataFrame(model.history.history)\n",
    "lossdf.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 899,
     "status": "ok",
     "timestamp": 1657211111401,
     "user": {
      "displayName": "Darshan Darshu",
      "userId": "08066444614316366436"
     },
     "user_tz": -330
    },
    "id": "rJFvM7warXHh"
   },
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "\n",
    "model.add(Dense(units=30,activation=\"relu\"))\n",
    "model.add(Dense(units=15,activation=\"relu\"))\n",
    "\n",
    "model.add(Dense(units=1,activation=\"sigmoid\"))\n",
    "\n",
    "model.compile(optimizer=\"adam\",loss=\"binary_crossentropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 420,
     "status": "ok",
     "timestamp": 1657211115253,
     "user": {
      "displayName": "Darshan Darshu",
      "userId": "08066444614316366436"
     },
     "user_tz": -330
    },
    "id": "rFLj3ERKslyj"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "earlystop=EarlyStopping(monitor=\"val_loss\",mode=\"min\",verbose=1,patience=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4221,
     "status": "ok",
     "timestamp": 1657211122600,
     "user": {
      "displayName": "Darshan Darshu",
      "userId": "08066444614316366436"
     },
     "user_tz": -330
    },
    "id": "tpC2GQb7wNr5",
    "outputId": "42a3f77b-a687-4730-d097-cf8784c2b9f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      "13/13 [==============================] - 1s 14ms/step - loss: 0.6475 - val_loss: 0.5383\n",
      "Epoch 2/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4540 - val_loss: 0.4087\n",
      "Epoch 3/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3390 - val_loss: 0.3232\n",
      "Epoch 4/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.2660 - val_loss: 0.2629\n",
      "Epoch 5/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.2139 - val_loss: 0.2214\n",
      "Epoch 6/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1782 - val_loss: 0.1910\n",
      "Epoch 7/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1523 - val_loss: 0.1689\n",
      "Epoch 8/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1330 - val_loss: 0.1516\n",
      "Epoch 9/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1178 - val_loss: 0.1383\n",
      "Epoch 10/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1053 - val_loss: 0.1279\n",
      "Epoch 11/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0955 - val_loss: 0.1199\n",
      "Epoch 12/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0862 - val_loss: 0.1137\n",
      "Epoch 13/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0792 - val_loss: 0.1086\n",
      "Epoch 14/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0736 - val_loss: 0.1047\n",
      "Epoch 15/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0683 - val_loss: 0.1014\n",
      "Epoch 16/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0639 - val_loss: 0.0990\n",
      "Epoch 17/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0599 - val_loss: 0.0973\n",
      "Epoch 18/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0567 - val_loss: 0.0962\n",
      "Epoch 19/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0536 - val_loss: 0.0944\n",
      "Epoch 20/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0509 - val_loss: 0.0927\n",
      "Epoch 21/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0483 - val_loss: 0.0920\n",
      "Epoch 22/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0460 - val_loss: 0.0911\n",
      "Epoch 23/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0440 - val_loss: 0.0903\n",
      "Epoch 24/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0422 - val_loss: 0.0898\n",
      "Epoch 25/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0405 - val_loss: 0.0889\n",
      "Epoch 26/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0386 - val_loss: 0.0882\n",
      "Epoch 27/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0374 - val_loss: 0.0879\n",
      "Epoch 28/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0360 - val_loss: 0.0881\n",
      "Epoch 29/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0347 - val_loss: 0.0871\n",
      "Epoch 30/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0336 - val_loss: 0.0879\n",
      "Epoch 31/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0325 - val_loss: 0.0877\n",
      "Epoch 32/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0315 - val_loss: 0.0887\n",
      "Epoch 33/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0304 - val_loss: 0.0896\n",
      "Epoch 34/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0297 - val_loss: 0.0895\n",
      "Epoch 35/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0288 - val_loss: 0.0901\n",
      "Epoch 36/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0279 - val_loss: 0.0893\n",
      "Epoch 37/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0269 - val_loss: 0.0893\n",
      "Epoch 38/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0261 - val_loss: 0.0895\n",
      "Epoch 39/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0254 - val_loss: 0.0894\n",
      "Epoch 40/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0247 - val_loss: 0.0904\n",
      "Epoch 41/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0239 - val_loss: 0.0910\n",
      "Epoch 42/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0232 - val_loss: 0.0902\n",
      "Epoch 43/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0225 - val_loss: 0.0910\n",
      "Epoch 44/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0218 - val_loss: 0.0919\n",
      "Epoch 45/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0214 - val_loss: 0.0920\n",
      "Epoch 46/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0207 - val_loss: 0.0915\n",
      "Epoch 47/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0198 - val_loss: 0.0928\n",
      "Epoch 48/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0192 - val_loss: 0.0933\n",
      "Epoch 49/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0186 - val_loss: 0.0947\n",
      "Epoch 50/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0179 - val_loss: 0.0939\n",
      "Epoch 51/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0172 - val_loss: 0.0944\n",
      "Epoch 52/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0166 - val_loss: 0.0955\n",
      "Epoch 53/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0161 - val_loss: 0.0950\n",
      "Epoch 54/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0155 - val_loss: 0.0970\n",
      "Epoch 54: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f267f4bef50>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(xtrain,ytrain,epochs=600,validation_data=(xtest,ytest),callbacks=[earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "executionInfo": {
     "elapsed": 4640,
     "status": "ok",
     "timestamp": 1657211130577,
     "user": {
      "displayName": "Darshan Darshu",
      "userId": "08066444614316366436"
     },
     "user_tz": -330
    },
    "id": "bNyBIlPtwsnT",
    "outputId": "6f466beb-4b58-4fad-d661-b2bc128fbbd7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f267f336390>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lossdf=pd.DataFrame(model.history.history)\n",
    "lossdf.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1657211133312,
     "user": {
      "displayName": "Darshan Darshu",
      "userId": "08066444614316366436"
     },
     "user_tz": -330
    },
    "id": "PxhgV-Cdyme6"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1657211137537,
     "user": {
      "displayName": "Darshan Darshu",
      "userId": "08066444614316366436"
     },
     "user_tz": -330
    },
    "id": "vqdnJlSGwy6f"
   },
   "outputs": [],
   "source": [
    "\n",
    "model=Sequential()\n",
    "\n",
    "model.add(Dense(units=30,activation=\"relu\"))\n",
    "model.add(Dropout(rate=0.5))\n",
    "\n",
    "model.add(Dense(units=15,activation=\"relu\"))\n",
    "model.add(Dropout(rate=0.5))\n",
    "\n",
    "model.add(Dense(units=1,activation=\"sigmoid\"))\n",
    "\n",
    "model.compile(optimizer=\"adam\",loss=\"binary_crossentropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5759,
     "status": "ok",
     "timestamp": 1657211147468,
     "user": {
      "displayName": "Darshan Darshu",
      "userId": "08066444614316366436"
     },
     "user_tz": -330
    },
    "id": "8CdWrDMBylK7",
    "outputId": "68e07129-8747-4526-c817-11759572ad17"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      "13/13 [==============================] - 2s 15ms/step - loss: 0.7885 - val_loss: 0.5852\n",
      "Epoch 2/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6290 - val_loss: 0.4988\n",
      "Epoch 3/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.5783 - val_loss: 0.4456\n",
      "Epoch 4/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5479 - val_loss: 0.4027\n",
      "Epoch 5/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4794 - val_loss: 0.3656\n",
      "Epoch 6/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4920 - val_loss: 0.3368\n",
      "Epoch 7/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4658 - val_loss: 0.3114\n",
      "Epoch 8/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.3959 - val_loss: 0.2901\n",
      "Epoch 9/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.3674 - val_loss: 0.2676\n",
      "Epoch 10/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3773 - val_loss: 0.2468\n",
      "Epoch 11/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3470 - val_loss: 0.2277\n",
      "Epoch 12/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3398 - val_loss: 0.2120\n",
      "Epoch 13/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.3393 - val_loss: 0.1975\n",
      "Epoch 14/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3053 - val_loss: 0.1833\n",
      "Epoch 15/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2804 - val_loss: 0.1720\n",
      "Epoch 16/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2977 - val_loss: 0.1616\n",
      "Epoch 17/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2341 - val_loss: 0.1524\n",
      "Epoch 18/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2500 - val_loss: 0.1445\n",
      "Epoch 19/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2516 - val_loss: 0.1381\n",
      "Epoch 20/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2357 - val_loss: 0.1327\n",
      "Epoch 21/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2450 - val_loss: 0.1281\n",
      "Epoch 22/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.2136 - val_loss: 0.1242\n",
      "Epoch 23/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1890 - val_loss: 0.1205\n",
      "Epoch 24/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2316 - val_loss: 0.1167\n",
      "Epoch 25/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.2108 - val_loss: 0.1134\n",
      "Epoch 26/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1914 - val_loss: 0.1108\n",
      "Epoch 27/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1971 - val_loss: 0.1080\n",
      "Epoch 28/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1822 - val_loss: 0.1063\n",
      "Epoch 29/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1944 - val_loss: 0.1049\n",
      "Epoch 30/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1485 - val_loss: 0.1047\n",
      "Epoch 31/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1625 - val_loss: 0.1044\n",
      "Epoch 32/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1668 - val_loss: 0.1042\n",
      "Epoch 33/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1450 - val_loss: 0.1034\n",
      "Epoch 34/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1339 - val_loss: 0.1032\n",
      "Epoch 35/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1485 - val_loss: 0.1035\n",
      "Epoch 36/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1413 - val_loss: 0.1033\n",
      "Epoch 37/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1197 - val_loss: 0.1035\n",
      "Epoch 38/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1403 - val_loss: 0.1036\n",
      "Epoch 39/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1304 - val_loss: 0.1038\n",
      "Epoch 40/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1106 - val_loss: 0.1041\n",
      "Epoch 41/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1359 - val_loss: 0.1053\n",
      "Epoch 42/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1268 - val_loss: 0.1060\n",
      "Epoch 43/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1317 - val_loss: 0.1059\n",
      "Epoch 44/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1280 - val_loss: 0.1063\n",
      "Epoch 45/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1160 - val_loss: 0.1062\n",
      "Epoch 46/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1290 - val_loss: 0.1059\n",
      "Epoch 47/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1268 - val_loss: 0.1060\n",
      "Epoch 48/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1204 - val_loss: 0.1068\n",
      "Epoch 49/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1179 - val_loss: 0.1068\n",
      "Epoch 50/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1252 - val_loss: 0.1074\n",
      "Epoch 51/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1362 - val_loss: 0.1082\n",
      "Epoch 52/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0928 - val_loss: 0.1082\n",
      "Epoch 53/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1037 - val_loss: 0.1087\n",
      "Epoch 54/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1297 - val_loss: 0.1096\n",
      "Epoch 55/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1203 - val_loss: 0.1108\n",
      "Epoch 56/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1149 - val_loss: 0.1085\n",
      "Epoch 57/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1230 - val_loss: 0.1083\n",
      "Epoch 58/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1071 - val_loss: 0.1084\n",
      "Epoch 59/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1201 - val_loss: 0.1089\n",
      "Epoch 59: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f267f270050>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(xtrain,ytrain,epochs=600,validation_data=(xtest,ytest),callbacks=[earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "executionInfo": {
     "elapsed": 2790,
     "status": "ok",
     "timestamp": 1657211154645,
     "user": {
      "displayName": "Darshan Darshu",
      "userId": "08066444614316366436"
     },
     "user_tz": -330
    },
    "id": "Tj4o0CogzRon",
    "outputId": "0a8bace6-4b7f-4285-dbf7-e72304a5ca00"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f267dbe5450>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lossdf=pd.DataFrame(model.history.history)\n",
    "lossdf.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 1044,
     "status": "ok",
     "timestamp": 1657211158632,
     "user": {
      "displayName": "Darshan Darshu",
      "userId": "08066444614316366436"
     },
     "user_tz": -330
    },
    "id": "RvHekn1o0HHe"
   },
   "outputs": [],
   "source": [
    "ypred=model.predict(xtest)\n",
    "ypred=ypred>0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1657211159548,
     "user": {
      "displayName": "Darshan Darshu",
      "userId": "08066444614316366436"
     },
     "user_tz": -330
    },
    "id": "0fIqETvZ2J0k",
    "outputId": "a65446e3-54ae-4220-bbf3-ce68707f17a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.94        63\n",
      "           1       0.96      0.97      0.97       108\n",
      "\n",
      "    accuracy                           0.96       171\n",
      "   macro avg       0.96      0.95      0.96       171\n",
      "weighted avg       0.96      0.96      0.96       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(ytest,ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0-jdsGSt2WzK"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOHQ2N5MJSItAe4tBLUP0X9",
   "collapsed_sections": [],
   "mount_file_id": "11aFvhGSIKXVPWPyPnlP7YS7XOjbzzSO0",
   "name": "cancer_classification",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
